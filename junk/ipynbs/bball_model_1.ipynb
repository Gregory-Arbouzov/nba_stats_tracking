{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "\n",
    "import random\n",
    "\n",
    "import psycopg2\n",
    "#from config import config\n",
    "from configparser import ConfigParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekend TODO\n",
    "\n",
    "# implement team/g - oppenent/g \n",
    "\n",
    "# try to normalize by season / playoffs\n",
    "\n",
    "# Do some visualization to map league trends\n",
    "\n",
    "# Look into how often sportbooks accurately predict the winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Sectionpostgresql is not found in the db/database.ini file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not found in the \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(section, filename))\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(db)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mconfig\u001b[0;34m(filename, section)\u001b[0m\n\u001b[1;32m     11\u001b[0m         db[param[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m param[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m is not found in the \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(section, filename))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(db)\n",
      "\u001b[0;31mException\u001b[0m: Sectionpostgresql is not found in the db/database.ini file"
     ]
    }
   ],
   "source": [
    "def config(filename = 'db/database.ini', section = 'postgresql'):\n",
    "    parser = ConfigParser()\n",
    "    parser.read(filename)\n",
    "\n",
    "    db = {}\n",
    "\n",
    "    if parser.has_section(section):\n",
    "        params = parser.items(section)\n",
    "\n",
    "        for param in params:\n",
    "            db[param[0]] = param[1]\n",
    "\n",
    "    else:\n",
    "        raise Exception('Section{0} is not found in the {1} file'.format(section, filename))\n",
    "    \n",
    "    return(db)\n",
    "\n",
    "config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_results_columns = ['id',\n",
    "    'visitor',\n",
    "    'home',\n",
    "    'dates',\n",
    "    'visitor_score',\n",
    "    'home_score']\n",
    "\n",
    "yearly_team_stats_columns = ['id',\n",
    "    'player',\n",
    "    'mp', \n",
    "    'fg', \n",
    "    'fga', \n",
    "    'fg_pct', \n",
    "    'fg3', \n",
    "    'fg3a', \n",
    "    'fg3_pct',\n",
    "    'fg2', \n",
    "    'fg2a', \n",
    "    'fg2_pct', \n",
    "    'ft', \n",
    "    'fta', \n",
    "    'ft_pct', \n",
    "    'orb', \n",
    "    'drb', \n",
    "    'trb',\n",
    "    'ast', \n",
    "    'stl', \n",
    "    'blk', \n",
    "    'tov', \n",
    "    'pf', \n",
    "    'pts', \n",
    "    'team', \n",
    "    'year']\n",
    "\n",
    "yearly_opponent_stats_columns = ['id',\n",
    "    'player',\n",
    "    'mp', \n",
    "    'fg', \n",
    "    'fga', \n",
    "    'fg_pct', \n",
    "    'fg3', \n",
    "    'fg3a', \n",
    "    'fg3_pct',\n",
    "    'fg2', \n",
    "    'fg2a', \n",
    "    'fg2_pct', \n",
    "    'ft', \n",
    "    'fta', \n",
    "    'ft_pct', \n",
    "    'orb', \n",
    "    'drb', \n",
    "    'trb',\n",
    "    'ast', \n",
    "    'stl', \n",
    "    'blk', \n",
    "    'tov', \n",
    "    'pf', \n",
    "    'pts', \n",
    "    'team', \n",
    "    'year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_to_dataframe(conn, query, column_names):\n",
    "   cursor = conn.cursor()\n",
    "   try:\n",
    "      cursor.execute(query)\n",
    "      tuples_list = cursor.fetchall()\n",
    "      cursor.close()\n",
    "      df = pd.DataFrame(tuples_list, columns=column_names)\n",
    "      return df\n",
    "   except (Exception, psycopg2.DatabaseError) as error:\n",
    "      print(\"Error: \" + str(error))\n",
    "      cursor.close()\n",
    "      return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#game_results_sql_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connecting to postgresql database...\n",
      "df created\n",
      "database connection terminated\n",
      "connecting to postgresql database...\n",
      "df created\n",
      "database connection terminated\n",
      "connecting to postgresql database...\n",
      "df created\n",
      "database connection terminated\n"
     ]
    }
   ],
   "source": [
    "def connect(query, columns):\n",
    "    connection = None\n",
    "    try:\n",
    "        params = config()\n",
    "        #print(params)\n",
    "        print('connecting to postgresql database...')\n",
    "        connection = psycopg2.connect(**params)\n",
    "       \n",
    "        # create cursor\n",
    "        cursor = connection.cursor()\n",
    "      \n",
    "\n",
    "        try:\n",
    "            df = sql_to_dataframe(connection, query, columns)\n",
    " \n",
    "            print(\"df created\")\n",
    "            return df\n",
    "\n",
    "            \n",
    "        except (Exception, psycopg2.DatabaseError) as error:\n",
    "            #os.remove(tmp_df)\n",
    "            print(\"Error: %s\" % error)\n",
    "            connection.rollback()\n",
    "            cursor.close()\n",
    "            return 1\n",
    "    \n",
    "    except(Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "    \n",
    "    finally:\n",
    "        if connection is not None:\n",
    "            connection.close()\n",
    "            print('database connection terminated')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    game_results_sql_df = connect('select * from game_results', game_results_columns)\n",
    "    team_stats_sql_df = connect('select * from yearly_team_per_game_stats', yearly_team_stats_columns)\n",
    "    opponent_stats_sql_df = connect('select * from yearly_opponent_per_game_stats', yearly_opponent_stats_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitor</th>\n",
       "      <th>home</th>\n",
       "      <th>dates</th>\n",
       "      <th>visitor_score</th>\n",
       "      <th>home_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHIBOS20221018</td>\n",
       "      <td>PHI</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20221018</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LALGSW20221018</td>\n",
       "      <td>LAL</td>\n",
       "      <td>GSW</td>\n",
       "      <td>20221018</td>\n",
       "      <td>109</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORLDET20221019</td>\n",
       "      <td>ORL</td>\n",
       "      <td>DET</td>\n",
       "      <td>20221019</td>\n",
       "      <td>109</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASIND20221019</td>\n",
       "      <td>WAS</td>\n",
       "      <td>IND</td>\n",
       "      <td>20221019</td>\n",
       "      <td>114</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOUATL20221019</td>\n",
       "      <td>HOU</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20221019</td>\n",
       "      <td>107</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>MIASAS20140605</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140605</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>MIASAS20140608</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140608</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>SASMIA20140610</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20140610</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>SASMIA20140612</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20140612</td>\n",
       "      <td>107</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>MIASAS20140615</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140615</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id visitor home     dates  visitor_score  home_score\n",
       "0      PHIBOS20221018     PHI  BOS  20221018            117         126\n",
       "1      LALGSW20221018     LAL  GSW  20221018            109         123\n",
       "2      ORLDET20221019     ORL  DET  20221019            109         113\n",
       "3      WASIND20221019     WAS  IND  20221019            114         107\n",
       "4      HOUATL20221019     HOU  ATL  20221019            107         117\n",
       "...               ...     ...  ...       ...            ...         ...\n",
       "12994  MIASAS20140605     MIA  SAS  20140605             95         110\n",
       "12995  MIASAS20140608     MIA  SAS  20140608             98          96\n",
       "12996  SASMIA20140610     SAS  MIA  20140610            111          92\n",
       "12997  SASMIA20140612     SAS  MIA  20140612            107          86\n",
       "12998  MIASAS20140615     MIA  SAS  20140615             87         104\n",
       "\n",
       "[12999 rows x 6 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_results_sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2</th>\n",
       "      <th>...</th>\n",
       "      <th>drb</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOR2014</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>243.4</td>\n",
       "      <td>36.5</td>\n",
       "      <td>81.9</td>\n",
       "      <td>0.445</td>\n",
       "      <td>8.7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.372</td>\n",
       "      <td>27.8</td>\n",
       "      <td>...</td>\n",
       "      <td>31.1</td>\n",
       "      <td>42.5</td>\n",
       "      <td>21.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOR2015</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>37.9</td>\n",
       "      <td>83.3</td>\n",
       "      <td>0.455</td>\n",
       "      <td>8.9</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.352</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>41.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>104.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS2014</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>240.6</td>\n",
       "      <td>36.5</td>\n",
       "      <td>83.9</td>\n",
       "      <td>0.435</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>29.5</td>\n",
       "      <td>...</td>\n",
       "      <td>30.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>96.2</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS2015</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.4</td>\n",
       "      <td>38.9</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0.443</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.327</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>32.7</td>\n",
       "      <td>43.8</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>101.4</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYK2014</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>36.9</td>\n",
       "      <td>82.2</td>\n",
       "      <td>0.449</td>\n",
       "      <td>9.3</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.372</td>\n",
       "      <td>27.7</td>\n",
       "      <td>...</td>\n",
       "      <td>29.7</td>\n",
       "      <td>40.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>98.6</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>HOU2023</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>40.6</td>\n",
       "      <td>88.9</td>\n",
       "      <td>0.457</td>\n",
       "      <td>10.4</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.327</td>\n",
       "      <td>30.2</td>\n",
       "      <td>...</td>\n",
       "      <td>32.9</td>\n",
       "      <td>46.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>110.7</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>NOP2020</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.6</td>\n",
       "      <td>91.6</td>\n",
       "      <td>0.465</td>\n",
       "      <td>13.6</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.370</td>\n",
       "      <td>28.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35.4</td>\n",
       "      <td>46.5</td>\n",
       "      <td>26.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>115.8</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NOP2021</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.5</td>\n",
       "      <td>89.1</td>\n",
       "      <td>0.477</td>\n",
       "      <td>10.6</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.348</td>\n",
       "      <td>31.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35.7</td>\n",
       "      <td>47.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>NOP2022</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>40.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.457</td>\n",
       "      <td>10.6</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0.332</td>\n",
       "      <td>29.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>45.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>109.3</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>NOP2023</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>87.6</td>\n",
       "      <td>0.480</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.364</td>\n",
       "      <td>31.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.1</td>\n",
       "      <td>43.7</td>\n",
       "      <td>25.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.5</td>\n",
       "      <td>114.4</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  player     mp    fg   fga  fg_pct   fg3  fg3a  fg3_pct   fg2  \\\n",
       "0    TOR2014  Team/G  243.4  36.5  81.9   0.445   8.7  23.4    0.372  27.8   \n",
       "1    TOR2015  Team/G  242.1  37.9  83.3   0.455   8.9  25.1    0.352  29.0   \n",
       "2    BOS2014  Team/G  240.6  36.5  83.9   0.435   7.0  21.1    0.333  29.5   \n",
       "3    BOS2015  Team/G  242.4  38.9  87.9   0.443   8.0  24.6    0.327  30.9   \n",
       "4    NYK2014  Team/G  242.1  36.9  82.2   0.449   9.3  24.9    0.372  27.7   \n",
       "..       ...     ...    ...   ...   ...     ...   ...   ...      ...   ...   \n",
       "294  HOU2023  Team/G  240.9  40.6  88.9   0.457  10.4  31.9    0.327  30.2   \n",
       "295  NOP2020  Team/G  242.1  42.6  91.6   0.465  13.6  36.9    0.370  28.9   \n",
       "296  NOP2021  Team/G  242.1  42.5  89.1   0.477  10.6  30.4    0.348  31.9   \n",
       "297  NOP2022  Team/G  240.9  40.2  88.0   0.457  10.6  32.1    0.332  29.5   \n",
       "298  NOP2023  Team/G  242.1  42.0  87.6   0.480  11.0  30.1    0.364  31.1   \n",
       "\n",
       "     ...   drb   trb   ast  stl  blk   tov    pf    pts  team  year  \n",
       "0    ...  31.1  42.5  21.2  7.0  4.2  14.1  23.0  101.3   TOR  2014  \n",
       "1    ...  30.8  41.5  20.7  7.5  4.4  12.9  20.9  104.0   TOR  2015  \n",
       "2    ...  30.5  42.5  21.0  7.1  4.2  15.4  21.3   96.2   BOS  2014  \n",
       "3    ...  32.7  43.8  24.5  8.2  3.6  13.8  21.2  101.4   BOS  2015  \n",
       "4    ...  29.7  40.3  20.0  7.7  4.5  13.0  22.1   98.6   NYK  2014  \n",
       "..   ...   ...   ...   ...  ...  ...   ...   ...    ...   ...   ...  \n",
       "294  ...  32.9  46.3  22.4  7.3  4.6  16.2  20.5  110.7   HOU  2023  \n",
       "295  ...  35.4  46.5  26.8  7.5  5.0  16.4  21.2  115.8   NOP  2020  \n",
       "296  ...  35.7  47.4  26.0  7.6  4.4  14.6  18.0  114.6   NOP  2021  \n",
       "297  ...  33.2  45.2  25.0  8.3  4.0  14.1  19.7  109.3   NOP  2022  \n",
       "298  ...  33.1  43.7  25.9  8.3  4.1  14.6  20.5  114.4   NOP  2023  \n",
       "\n",
       "[299 rows x 26 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_stats_sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2</th>\n",
       "      <th>...</th>\n",
       "      <th>drb</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOR2014</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>243.4</td>\n",
       "      <td>36.1</td>\n",
       "      <td>80.2</td>\n",
       "      <td>0.450</td>\n",
       "      <td>6.9</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.360</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOR2015</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>0.459</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.346</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>31.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>100.9</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS2014</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>240.6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>81.4</td>\n",
       "      <td>0.465</td>\n",
       "      <td>6.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.347</td>\n",
       "      <td>31.2</td>\n",
       "      <td>...</td>\n",
       "      <td>31.7</td>\n",
       "      <td>42.3</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>100.7</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS2015</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.4</td>\n",
       "      <td>38.1</td>\n",
       "      <td>84.7</td>\n",
       "      <td>0.450</td>\n",
       "      <td>7.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>30.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.8</td>\n",
       "      <td>44.7</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>15.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>101.2</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYK2014</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>35.8</td>\n",
       "      <td>78.1</td>\n",
       "      <td>0.458</td>\n",
       "      <td>8.7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.371</td>\n",
       "      <td>27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>99.4</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>HOU2023</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>42.4</td>\n",
       "      <td>88.1</td>\n",
       "      <td>0.482</td>\n",
       "      <td>14.5</td>\n",
       "      <td>38.8</td>\n",
       "      <td>0.374</td>\n",
       "      <td>27.9</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>20.6</td>\n",
       "      <td>118.6</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>NOP2020</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.7</td>\n",
       "      <td>91.8</td>\n",
       "      <td>0.465</td>\n",
       "      <td>12.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>0.361</td>\n",
       "      <td>30.5</td>\n",
       "      <td>...</td>\n",
       "      <td>34.7</td>\n",
       "      <td>44.8</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>117.1</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NOP2021</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>41.9</td>\n",
       "      <td>89.3</td>\n",
       "      <td>0.469</td>\n",
       "      <td>14.5</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>27.4</td>\n",
       "      <td>...</td>\n",
       "      <td>32.9</td>\n",
       "      <td>41.8</td>\n",
       "      <td>25.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>13.3</td>\n",
       "      <td>21.3</td>\n",
       "      <td>114.9</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>NOP2022</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>40.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>0.471</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.365</td>\n",
       "      <td>27.3</td>\n",
       "      <td>...</td>\n",
       "      <td>32.5</td>\n",
       "      <td>41.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>110.3</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>NOP2023</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>40.9</td>\n",
       "      <td>86.6</td>\n",
       "      <td>0.472</td>\n",
       "      <td>12.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.339</td>\n",
       "      <td>28.7</td>\n",
       "      <td>...</td>\n",
       "      <td>32.1</td>\n",
       "      <td>41.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      player     mp    fg   fga  fg_pct   fg3  fg3a  fg3_pct  \\\n",
       "0    TOR2014  Opponent/G  243.4  36.1  80.2   0.450   6.9  19.2    0.360   \n",
       "1    TOR2015  Opponent/G  242.1  38.0  82.8   0.459   7.7  22.3    0.346   \n",
       "2    BOS2014  Opponent/G  240.6  37.8  81.4   0.465   6.6  18.9    0.347   \n",
       "3    BOS2015  Opponent/G  242.4  38.1  84.7   0.450   7.4  22.0    0.336   \n",
       "4    NYK2014  Opponent/G  242.1  35.8  78.1   0.458   8.7  23.4    0.371   \n",
       "..       ...         ...    ...   ...   ...     ...   ...   ...      ...   \n",
       "294  HOU2023  Opponent/G  240.9  42.4  88.1   0.482  14.5  38.8    0.374   \n",
       "295  NOP2020  Opponent/G  242.1  42.7  91.8   0.465  12.2  33.9    0.361   \n",
       "296  NOP2021  Opponent/G  242.1  41.9  89.3   0.469  14.5  38.1    0.380   \n",
       "297  NOP2022  Opponent/G  240.9  40.3  85.5   0.471  13.0  35.5    0.365   \n",
       "298  NOP2023  Opponent/G  242.1  40.9  86.6   0.472  12.2  36.0    0.339   \n",
       "\n",
       "      fg2  ...   drb   trb   ast  stl  blk   tov    pf    pts  team  year  \n",
       "0    29.1  ...  30.5  41.0  21.0  7.3  4.3  14.9  22.1   98.0   TOR  2014  \n",
       "1    30.3  ...  31.2  42.5  22.8  6.9  5.0  14.4  20.3  100.9   TOR  2015  \n",
       "2    31.2  ...  31.7  42.3  22.1  7.4  4.5  14.2  19.1  100.7   BOS  2014  \n",
       "3    30.7  ...  33.8  44.7  21.9  7.1  5.3  15.1  18.8  101.2   BOS  2015  \n",
       "4    27.1  ...  31.7  42.0  19.7  6.3  3.4  14.5  19.6   99.4   NYK  2014  \n",
       "..    ...  ...   ...   ...   ...  ...  ...   ...   ...    ...   ...   ...  \n",
       "294  27.9  ...  31.0  41.5  26.1  8.8  6.2  13.2  20.6  118.6   HOU  2023  \n",
       "295  30.5  ...  34.7  44.8  24.5  8.5  4.8  14.5  21.1  117.1   NOP  2020  \n",
       "296  27.4  ...  32.9  41.8  25.9  7.7  5.9  13.3  21.3  114.9   NOP  2021  \n",
       "297  27.3  ...  32.5  41.8  24.9  7.4  4.8  14.2  20.5  110.3   NOP  2022  \n",
       "298  28.7  ...  32.1  41.8  24.9  7.3  4.7  15.0  20.4  112.5   NOP  2023  \n",
       "\n",
       "[299 rows x 26 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opponent_stats_sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team_stats_df = pd.read_csv('data/team_stats.csv')\n",
    "#game_results_13_14_df = pd.read_csv('data/game_results_2013_2014.csv')\n",
    "#game_results_15_16_df = pd.read_csv('data/game_results_2015_2016.csv')\n",
    "#game_results_17_18_df = pd.read_csv('data/game_results_2017_2018.csv')\n",
    "#game_results_19_df = pd.read_csv('data/game_results_2019.csv')\n",
    "#game_results_21_22_df = pd.read_csv('data/game_results_2021_2022.csv')\n",
    "#game_results_23_df = pd.read_csv('data/game_results_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#money_line_df = pd.read_csv('data/betting_data/nba_betting_money_line.csv')\n",
    "#betting_spread_df = pd.read_csv('data/betting_data/nba_betting_spread.csv')\n",
    "#betting_totals_df = pd.read_csv('data/betting_data/nba_betting_spread.csv')\n",
    "#all_games_df = pd.read_csv('data/betting_data/nba_games_all.csv')\n",
    "#all_players_df = pd.read_csv('data/betting_data/nba_players_all.csv')\n",
    "#all_players_game_stats_df = pd.read_csv('data/betting_data/nba_players_game_stats.csv')\n",
    "#all_teams_df = pd.read_csv('data/betting_data/nba_teams_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spread_and_scores_df = all_games_df.merge(betting_spread_df, on = 'game_id')\n",
    "#spread_and_scores_w_teams_df = spread_and_scores_df.merge(all_teams_df, on = 'team_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spread_and_scores_w_teams_df = spread_and_scores_df.merge(all_teams_df, on = 'team_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bovada_spreads = spread_and_scores_df[spread_and_scores_df['book_name'] == 'Bovada']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bovada_spreads.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bovada 2009 accuracy\n",
    "#len(bovada_spreads[(bovada_spreads['wl'] == 'W') & (bovada_spreads['season'] == '2008-09') & (bovada_spreads['spread1'] > 0)])/len(bovada_spreads[(bovada_spreads['wl'] == 'W') & (bovada_spreads['season'] == '2008-09')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bovada all time accuracy\n",
    "#len(bovada_spreads[(bovada_spreads['wl'] == 'W') & (bovada_spreads['spread1'] > 0)])/len(bovada_spreads[(bovada_spreads['wl'] == 'W')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_game_results_df = pd.concat([game_results_13_14_df, game_results_15_16_df, game_results_17_18_df, game_results_19_df, game_results_21_22_df, game_results_23_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team_stats_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "#all_game_results_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "#all_game_results_df.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_game_results_df = game_results_sql_df\n",
    "team_per_game_stats_df = team_stats_sql_df\n",
    "opponent_per_game_stats_df = opponent_stats_sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team_per_game_stats_df = team_stats_df[team_stats_df['player'] == 'Team/G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opponent_per_game_stats_df = team_stats_df[team_stats_df['player'] == 'Opponent/G']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#team_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2</th>\n",
       "      <th>...</th>\n",
       "      <th>drb</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOR2014</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>243.4</td>\n",
       "      <td>36.5</td>\n",
       "      <td>81.9</td>\n",
       "      <td>0.445</td>\n",
       "      <td>8.7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.372</td>\n",
       "      <td>27.8</td>\n",
       "      <td>...</td>\n",
       "      <td>31.1</td>\n",
       "      <td>42.5</td>\n",
       "      <td>21.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOR2015</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>37.9</td>\n",
       "      <td>83.3</td>\n",
       "      <td>0.455</td>\n",
       "      <td>8.9</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.352</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>30.8</td>\n",
       "      <td>41.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>104.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS2014</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>240.6</td>\n",
       "      <td>36.5</td>\n",
       "      <td>83.9</td>\n",
       "      <td>0.435</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>29.5</td>\n",
       "      <td>...</td>\n",
       "      <td>30.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>96.2</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS2015</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.4</td>\n",
       "      <td>38.9</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0.443</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.327</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>32.7</td>\n",
       "      <td>43.8</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>101.4</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYK2014</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>36.9</td>\n",
       "      <td>82.2</td>\n",
       "      <td>0.449</td>\n",
       "      <td>9.3</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.372</td>\n",
       "      <td>27.7</td>\n",
       "      <td>...</td>\n",
       "      <td>29.7</td>\n",
       "      <td>40.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>98.6</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>HOU2023</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>40.6</td>\n",
       "      <td>88.9</td>\n",
       "      <td>0.457</td>\n",
       "      <td>10.4</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.327</td>\n",
       "      <td>30.2</td>\n",
       "      <td>...</td>\n",
       "      <td>32.9</td>\n",
       "      <td>46.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>110.7</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>NOP2020</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.6</td>\n",
       "      <td>91.6</td>\n",
       "      <td>0.465</td>\n",
       "      <td>13.6</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.370</td>\n",
       "      <td>28.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35.4</td>\n",
       "      <td>46.5</td>\n",
       "      <td>26.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>115.8</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NOP2021</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.5</td>\n",
       "      <td>89.1</td>\n",
       "      <td>0.477</td>\n",
       "      <td>10.6</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.348</td>\n",
       "      <td>31.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35.7</td>\n",
       "      <td>47.4</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>114.6</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>NOP2022</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>40.2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.457</td>\n",
       "      <td>10.6</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0.332</td>\n",
       "      <td>29.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>45.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>109.3</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>NOP2023</td>\n",
       "      <td>Team/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>87.6</td>\n",
       "      <td>0.480</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.364</td>\n",
       "      <td>31.1</td>\n",
       "      <td>...</td>\n",
       "      <td>33.1</td>\n",
       "      <td>43.7</td>\n",
       "      <td>25.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.5</td>\n",
       "      <td>114.4</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  player     mp    fg   fga  fg_pct   fg3  fg3a  fg3_pct   fg2  \\\n",
       "0    TOR2014  Team/G  243.4  36.5  81.9   0.445   8.7  23.4    0.372  27.8   \n",
       "1    TOR2015  Team/G  242.1  37.9  83.3   0.455   8.9  25.1    0.352  29.0   \n",
       "2    BOS2014  Team/G  240.6  36.5  83.9   0.435   7.0  21.1    0.333  29.5   \n",
       "3    BOS2015  Team/G  242.4  38.9  87.9   0.443   8.0  24.6    0.327  30.9   \n",
       "4    NYK2014  Team/G  242.1  36.9  82.2   0.449   9.3  24.9    0.372  27.7   \n",
       "..       ...     ...    ...   ...   ...     ...   ...   ...      ...   ...   \n",
       "294  HOU2023  Team/G  240.9  40.6  88.9   0.457  10.4  31.9    0.327  30.2   \n",
       "295  NOP2020  Team/G  242.1  42.6  91.6   0.465  13.6  36.9    0.370  28.9   \n",
       "296  NOP2021  Team/G  242.1  42.5  89.1   0.477  10.6  30.4    0.348  31.9   \n",
       "297  NOP2022  Team/G  240.9  40.2  88.0   0.457  10.6  32.1    0.332  29.5   \n",
       "298  NOP2023  Team/G  242.1  42.0  87.6   0.480  11.0  30.1    0.364  31.1   \n",
       "\n",
       "     ...   drb   trb   ast  stl  blk   tov    pf    pts  team  year  \n",
       "0    ...  31.1  42.5  21.2  7.0  4.2  14.1  23.0  101.3   TOR  2014  \n",
       "1    ...  30.8  41.5  20.7  7.5  4.4  12.9  20.9  104.0   TOR  2015  \n",
       "2    ...  30.5  42.5  21.0  7.1  4.2  15.4  21.3   96.2   BOS  2014  \n",
       "3    ...  32.7  43.8  24.5  8.2  3.6  13.8  21.2  101.4   BOS  2015  \n",
       "4    ...  29.7  40.3  20.0  7.7  4.5  13.0  22.1   98.6   NYK  2014  \n",
       "..   ...   ...   ...   ...  ...  ...   ...   ...    ...   ...   ...  \n",
       "294  ...  32.9  46.3  22.4  7.3  4.6  16.2  20.5  110.7   HOU  2023  \n",
       "295  ...  35.4  46.5  26.8  7.5  5.0  16.4  21.2  115.8   NOP  2020  \n",
       "296  ...  35.7  47.4  26.0  7.6  4.4  14.6  18.0  114.6   NOP  2021  \n",
       "297  ...  33.2  45.2  25.0  8.3  4.0  14.1  19.7  109.3   NOP  2022  \n",
       "298  ...  33.1  43.7  25.9  8.3  4.1  14.6  20.5  114.4   NOP  2023  \n",
       "\n",
       "[299 rows x 26 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player</th>\n",
       "      <th>mp</th>\n",
       "      <th>fg</th>\n",
       "      <th>fga</th>\n",
       "      <th>fg_pct</th>\n",
       "      <th>fg3</th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2</th>\n",
       "      <th>...</th>\n",
       "      <th>drb</th>\n",
       "      <th>trb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>pts</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TOR2014</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>243.4</td>\n",
       "      <td>36.1</td>\n",
       "      <td>80.2</td>\n",
       "      <td>0.450</td>\n",
       "      <td>6.9</td>\n",
       "      <td>19.2</td>\n",
       "      <td>0.360</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.5</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TOR2015</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>0.459</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.346</td>\n",
       "      <td>30.3</td>\n",
       "      <td>...</td>\n",
       "      <td>31.2</td>\n",
       "      <td>42.5</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20.3</td>\n",
       "      <td>100.9</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOS2014</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>240.6</td>\n",
       "      <td>37.8</td>\n",
       "      <td>81.4</td>\n",
       "      <td>0.465</td>\n",
       "      <td>6.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.347</td>\n",
       "      <td>31.2</td>\n",
       "      <td>...</td>\n",
       "      <td>31.7</td>\n",
       "      <td>42.3</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>14.2</td>\n",
       "      <td>19.1</td>\n",
       "      <td>100.7</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOS2015</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.4</td>\n",
       "      <td>38.1</td>\n",
       "      <td>84.7</td>\n",
       "      <td>0.450</td>\n",
       "      <td>7.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>30.7</td>\n",
       "      <td>...</td>\n",
       "      <td>33.8</td>\n",
       "      <td>44.7</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>15.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>101.2</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NYK2014</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>35.8</td>\n",
       "      <td>78.1</td>\n",
       "      <td>0.458</td>\n",
       "      <td>8.7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.371</td>\n",
       "      <td>27.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.7</td>\n",
       "      <td>42.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>99.4</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>HOU2023</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>42.4</td>\n",
       "      <td>88.1</td>\n",
       "      <td>0.482</td>\n",
       "      <td>14.5</td>\n",
       "      <td>38.8</td>\n",
       "      <td>0.374</td>\n",
       "      <td>27.9</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>20.6</td>\n",
       "      <td>118.6</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>NOP2020</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>42.7</td>\n",
       "      <td>91.8</td>\n",
       "      <td>0.465</td>\n",
       "      <td>12.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>0.361</td>\n",
       "      <td>30.5</td>\n",
       "      <td>...</td>\n",
       "      <td>34.7</td>\n",
       "      <td>44.8</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>117.1</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NOP2021</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>41.9</td>\n",
       "      <td>89.3</td>\n",
       "      <td>0.469</td>\n",
       "      <td>14.5</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.380</td>\n",
       "      <td>27.4</td>\n",
       "      <td>...</td>\n",
       "      <td>32.9</td>\n",
       "      <td>41.8</td>\n",
       "      <td>25.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>13.3</td>\n",
       "      <td>21.3</td>\n",
       "      <td>114.9</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>NOP2022</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>240.9</td>\n",
       "      <td>40.3</td>\n",
       "      <td>85.5</td>\n",
       "      <td>0.471</td>\n",
       "      <td>13.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.365</td>\n",
       "      <td>27.3</td>\n",
       "      <td>...</td>\n",
       "      <td>32.5</td>\n",
       "      <td>41.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>110.3</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>NOP2023</td>\n",
       "      <td>Opponent/G</td>\n",
       "      <td>242.1</td>\n",
       "      <td>40.9</td>\n",
       "      <td>86.6</td>\n",
       "      <td>0.472</td>\n",
       "      <td>12.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.339</td>\n",
       "      <td>28.7</td>\n",
       "      <td>...</td>\n",
       "      <td>32.1</td>\n",
       "      <td>41.8</td>\n",
       "      <td>24.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      player     mp    fg   fga  fg_pct   fg3  fg3a  fg3_pct  \\\n",
       "0    TOR2014  Opponent/G  243.4  36.1  80.2   0.450   6.9  19.2    0.360   \n",
       "1    TOR2015  Opponent/G  242.1  38.0  82.8   0.459   7.7  22.3    0.346   \n",
       "2    BOS2014  Opponent/G  240.6  37.8  81.4   0.465   6.6  18.9    0.347   \n",
       "3    BOS2015  Opponent/G  242.4  38.1  84.7   0.450   7.4  22.0    0.336   \n",
       "4    NYK2014  Opponent/G  242.1  35.8  78.1   0.458   8.7  23.4    0.371   \n",
       "..       ...         ...    ...   ...   ...     ...   ...   ...      ...   \n",
       "294  HOU2023  Opponent/G  240.9  42.4  88.1   0.482  14.5  38.8    0.374   \n",
       "295  NOP2020  Opponent/G  242.1  42.7  91.8   0.465  12.2  33.9    0.361   \n",
       "296  NOP2021  Opponent/G  242.1  41.9  89.3   0.469  14.5  38.1    0.380   \n",
       "297  NOP2022  Opponent/G  240.9  40.3  85.5   0.471  13.0  35.5    0.365   \n",
       "298  NOP2023  Opponent/G  242.1  40.9  86.6   0.472  12.2  36.0    0.339   \n",
       "\n",
       "      fg2  ...   drb   trb   ast  stl  blk   tov    pf    pts  team  year  \n",
       "0    29.1  ...  30.5  41.0  21.0  7.3  4.3  14.9  22.1   98.0   TOR  2014  \n",
       "1    30.3  ...  31.2  42.5  22.8  6.9  5.0  14.4  20.3  100.9   TOR  2015  \n",
       "2    31.2  ...  31.7  42.3  22.1  7.4  4.5  14.2  19.1  100.7   BOS  2014  \n",
       "3    30.7  ...  33.8  44.7  21.9  7.1  5.3  15.1  18.8  101.2   BOS  2015  \n",
       "4    27.1  ...  31.7  42.0  19.7  6.3  3.4  14.5  19.6   99.4   NYK  2014  \n",
       "..    ...  ...   ...   ...   ...  ...  ...   ...   ...    ...   ...   ...  \n",
       "294  27.9  ...  31.0  41.5  26.1  8.8  6.2  13.2  20.6  118.6   HOU  2023  \n",
       "295  30.5  ...  34.7  44.8  24.5  8.5  4.8  14.5  21.1  117.1   NOP  2020  \n",
       "296  27.4  ...  32.9  41.8  25.9  7.7  5.9  13.3  21.3  114.9   NOP  2021  \n",
       "297  27.3  ...  32.5  41.8  24.9  7.4  4.8  14.2  20.5  110.3   NOP  2022  \n",
       "298  28.7  ...  32.1  41.8  24.9  7.3  4.7  15.0  20.4  112.5   NOP  2023  \n",
       "\n",
       "[299 rows x 26 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opponent_per_game_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should I only normalize the team/opponent status by season, or all together?\n",
    "# will start all together for now\n",
    "\n",
    "# how can home court advantage be factored into the model evaluation?\n",
    "\n",
    "# should I subtract team B's per game stats from team A's first (should opponent per game stats be factored into this somehow?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299 entries, 0 to 298\n",
      "Data columns (total 26 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       299 non-null    object \n",
      " 1   player   299 non-null    object \n",
      " 2   mp       299 non-null    float64\n",
      " 3   fg       299 non-null    float64\n",
      " 4   fga      299 non-null    float64\n",
      " 5   fg_pct   299 non-null    float64\n",
      " 6   fg3      299 non-null    float64\n",
      " 7   fg3a     299 non-null    float64\n",
      " 8   fg3_pct  299 non-null    float64\n",
      " 9   fg2      299 non-null    float64\n",
      " 10  fg2a     299 non-null    float64\n",
      " 11  fg2_pct  299 non-null    float64\n",
      " 12  ft       299 non-null    float64\n",
      " 13  fta      299 non-null    float64\n",
      " 14  ft_pct   299 non-null    float64\n",
      " 15  orb      299 non-null    float64\n",
      " 16  drb      299 non-null    float64\n",
      " 17  trb      299 non-null    float64\n",
      " 18  ast      299 non-null    float64\n",
      " 19  stl      299 non-null    float64\n",
      " 20  blk      299 non-null    float64\n",
      " 21  tov      299 non-null    float64\n",
      " 22  pf       299 non-null    float64\n",
      " 23  pts      299 non-null    float64\n",
      " 24  team     299 non-null    object \n",
      " 25  year     299 non-null    int64  \n",
      "dtypes: float64(22), int64(1), object(3)\n",
      "memory usage: 60.9+ KB\n"
     ]
    }
   ],
   "source": [
    "team_per_game_stats_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         TOR2014\n",
       "player      Team/G\n",
       "mp           243.4\n",
       "fg            36.5\n",
       "fga           81.9\n",
       "fg_pct       0.445\n",
       "fg3            8.7\n",
       "fg3a          23.4\n",
       "fg3_pct      0.372\n",
       "fg2           27.8\n",
       "fg2a          58.5\n",
       "fg2_pct      0.475\n",
       "ft            19.6\n",
       "fta           25.1\n",
       "ft_pct       0.782\n",
       "orb           11.4\n",
       "drb           31.1\n",
       "trb           42.5\n",
       "ast           21.2\n",
       "stl            7.0\n",
       "blk            4.2\n",
       "tov           14.1\n",
       "pf            23.0\n",
       "pts          101.3\n",
       "team           TOR\n",
       "year          2014\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ['fg3a', 'fg3_pct', 'fg2a', 'fg2_pct', 'fta', 'ft_pct', 'orb', 'drb', 'ast', 'stl', 'blk', 'tov', 'pf', 'team', 'year']\n",
    "team_per_game_stats_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_per_game_stats_df = team_per_game_stats_df[['fg3a', 'fg3_pct', 'fg2a', 'fg2_pct', 'fta', 'ft_pct', 'orb', 'drb', 'ast', 'stl', 'blk', 'tov', 'pf', 'team', 'year']].copy()\n",
    "team_per_game_stats_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/tfm_mmns5096hfr18knr3rp40000gp/T/ipykernel_689/2081457076.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  opponent_per_game_stats_df.drop_duplicates(inplace = True)\n"
     ]
    }
   ],
   "source": [
    "opponent_per_game_stats_df = opponent_per_game_stats_df[['fg3a', 'fg3_pct', 'fg2a', 'fg2_pct', 'fta', 'ft_pct', 'orb', 'drb', 'ast', 'stl', 'blk', 'tov', 'pf', 'team', 'year']]\n",
    "opponent_per_game_stats_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8e+00,  6.0e-03, -2.3e+00, -2.0e-03,  1.1e+00,  5.4e-02,\n",
       "        -5.0e-01, -4.0e-01, -2.1e+00,  6.0e-01, -6.0e-01, -1.5e+00,\n",
       "         6.0e-01]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == 'TOR') & (team_per_game_stats_df['year'] == 2015)].iloc[:,:-2]) - np.array(opponent_per_game_stats_df[(opponent_per_game_stats_df['team'] == 'TOR') & (opponent_per_game_stats_df['year'] == 2015)].iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.3e+00, -8.0e-03, -7.8e+00,  1.1e-02,  3.2e+00,  4.5e-02,\n",
       "         2.0e-01, -3.4e+00, -3.3e+00,  2.0e-01, -2.0e-01, -2.1e+00,\n",
       "         1.0e-01]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == 'TOR') & (team_per_game_stats_df['year'] == 2015)].iloc[:,:-2]) - np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == 'WAS') & (team_per_game_stats_df['year'] == 2015)].iloc[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_vs_opp_stats(team, season_year) : return np.subtract(np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == team) & (team_per_game_stats_df['year'] == season_year)].iloc[:,:-2]), np.array(opponent_per_game_stats_df[(opponent_per_game_stats_df['team'] == team) & (opponent_per_game_stats_df['year'] == season_year)].iloc[:,:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fg3a       2.600\n",
       "fg3_pct   -0.011\n",
       "fg2a       1.300\n",
       "fg2_pct   -0.011\n",
       "fta       -3.500\n",
       "ft_pct     0.016\n",
       "orb       -0.600\n",
       "drb       -3.800\n",
       "ast       -1.900\n",
       "stl        2.000\n",
       "blk       -0.200\n",
       "tov       -2.900\n",
       "pf         1.700\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(team_vs_opp_stats('TOR',2021)[0], index = team_per_game_stats_df.iloc[:,:-2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.4</td>\n",
       "      <td>0.372</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.475</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.782</td>\n",
       "      <td>11.4</td>\n",
       "      <td>31.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.1</td>\n",
       "      <td>0.352</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.499</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.787</td>\n",
       "      <td>10.7</td>\n",
       "      <td>30.8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>62.9</td>\n",
       "      <td>0.470</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.777</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.6</td>\n",
       "      <td>0.327</td>\n",
       "      <td>63.3</td>\n",
       "      <td>0.488</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.754</td>\n",
       "      <td>11.1</td>\n",
       "      <td>32.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.9</td>\n",
       "      <td>0.372</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.482</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.761</td>\n",
       "      <td>10.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fg3a  fg3_pct  fg2a  fg2_pct   fta  ft_pct   orb   drb   ast  stl  blk  \\\n",
       "0  23.4    0.372  58.5    0.475  25.1   0.782  11.4  31.1  21.2  7.0  4.2   \n",
       "1  25.1    0.352  58.2    0.499  24.6   0.787  10.7  30.8  20.7  7.5  4.4   \n",
       "2  21.1    0.333  62.9    0.470  20.8   0.777  12.0  30.5  21.0  7.1  4.2   \n",
       "3  24.6    0.327  63.3    0.488  20.5   0.754  11.1  32.7  24.5  8.2  3.6   \n",
       "4  24.9    0.372  57.3    0.482  20.4   0.761  10.6  29.7  20.0  7.7  4.5   \n",
       "\n",
       "    tov    pf team  year  \n",
       "0  14.1  23.0  TOR  2014  \n",
       "1  12.9  20.9  TOR  2015  \n",
       "2  15.4  21.3  BOS  2014  \n",
       "3  13.8  21.2  BOS  2015  \n",
       "4  13.0  22.1  NYK  2014  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats_diff_df = pd.DataFrame(data = team_per_game_stats_df.apply(lambda x: pd.Series(team_vs_opp_stats(x.team, x.year)[0], index = team_per_game_stats_df.iloc[:,:-2].columns), axis = 1), columns = team_per_game_stats_df.iloc[:,:-2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fg3a', 'fg3_pct', 'fg2a', 'fg2_pct', 'fta', 'ft_pct', 'orb', 'drb',\n",
       "       'ast', 'stl', 'blk', 'tov', 'pf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df.iloc[:,:-2].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.8</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.054</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.2</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.016</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>-6.9</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-7.7</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.009</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-3.4</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.003</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-5.9</td>\n",
       "      <td>0.025</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fg3a  fg3_pct  fg2a  fg2_pct  fta  ft_pct  orb  drb  ast  stl  blk  tov  \\\n",
       "0     4.2    0.012  -2.4   -0.003 -0.2   0.030  1.0  0.6  0.2 -0.3 -0.1 -0.8   \n",
       "1     2.8    0.006  -2.3   -0.002  1.1   0.054 -0.5 -0.4 -2.1  0.6 -0.6 -1.5   \n",
       "2     2.2   -0.014   0.4   -0.030 -3.5   0.016  1.4 -1.2 -1.1 -0.3 -0.3  1.2   \n",
       "3     2.6   -0.009   0.6   -0.002 -2.8  -0.001  0.2 -1.1  2.6  1.1 -1.7 -1.3   \n",
       "4     1.5    0.001   2.7   -0.014 -4.6  -0.004  0.3 -2.0  0.3  1.4  1.1 -1.5   \n",
       "..    ...      ...   ...      ...  ...     ...  ...  ...  ...  ...  ...  ...   \n",
       "294  -6.9   -0.047   7.6   -0.037  1.1  -0.040  2.9  1.9 -3.7 -1.5 -1.6  3.0   \n",
       "295   3.0    0.009  -3.2    0.002 -1.3  -0.060  1.0  0.7  2.3 -1.0  0.2  1.9   \n",
       "296  -7.7   -0.032   7.4    0.009  5.0  -0.061  2.8  2.8  0.1 -0.1 -1.5  1.3   \n",
       "297  -3.4   -0.033   5.9   -0.018  1.8   0.003  2.7  0.7  0.1  0.9 -0.8 -0.1   \n",
       "298  -5.9    0.025   6.9   -0.026  0.8   0.014  0.9  1.0  1.0  1.0 -0.6 -0.4   \n",
       "\n",
       "      pf  \n",
       "0    0.9  \n",
       "1    0.6  \n",
       "2    2.2  \n",
       "3    2.4  \n",
       "4    2.5  \n",
       "..   ...  \n",
       "294 -0.1  \n",
       "295  0.1  \n",
       "296 -3.3  \n",
       "297 -0.8  \n",
       "298  0.1  \n",
       "\n",
       "[299 rows x 13 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_stats_diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>team</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.4</td>\n",
       "      <td>0.372</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.475</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.782</td>\n",
       "      <td>11.4</td>\n",
       "      <td>31.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.1</td>\n",
       "      <td>0.352</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.499</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.787</td>\n",
       "      <td>10.7</td>\n",
       "      <td>30.8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>62.9</td>\n",
       "      <td>0.470</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.777</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>21.3</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.6</td>\n",
       "      <td>0.327</td>\n",
       "      <td>63.3</td>\n",
       "      <td>0.488</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.754</td>\n",
       "      <td>11.1</td>\n",
       "      <td>32.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.2</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.9</td>\n",
       "      <td>0.372</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.482</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.761</td>\n",
       "      <td>10.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>NYK</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>31.9</td>\n",
       "      <td>0.327</td>\n",
       "      <td>56.9</td>\n",
       "      <td>0.530</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.754</td>\n",
       "      <td>13.4</td>\n",
       "      <td>32.9</td>\n",
       "      <td>22.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>36.9</td>\n",
       "      <td>0.370</td>\n",
       "      <td>54.8</td>\n",
       "      <td>0.528</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.729</td>\n",
       "      <td>11.1</td>\n",
       "      <td>35.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>30.4</td>\n",
       "      <td>0.348</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.544</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.729</td>\n",
       "      <td>11.7</td>\n",
       "      <td>35.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>32.1</td>\n",
       "      <td>0.332</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.528</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.789</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>30.1</td>\n",
       "      <td>0.364</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.541</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.793</td>\n",
       "      <td>10.6</td>\n",
       "      <td>33.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.5</td>\n",
       "      <td>NOP</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fg3a  fg3_pct  fg2a  fg2_pct   fta  ft_pct   orb   drb   ast  stl  blk  \\\n",
       "0    23.4    0.372  58.5    0.475  25.1   0.782  11.4  31.1  21.2  7.0  4.2   \n",
       "1    25.1    0.352  58.2    0.499  24.6   0.787  10.7  30.8  20.7  7.5  4.4   \n",
       "2    21.1    0.333  62.9    0.470  20.8   0.777  12.0  30.5  21.0  7.1  4.2   \n",
       "3    24.6    0.327  63.3    0.488  20.5   0.754  11.1  32.7  24.5  8.2  3.6   \n",
       "4    24.9    0.372  57.3    0.482  20.4   0.761  10.6  29.7  20.0  7.7  4.5   \n",
       "..    ...      ...   ...      ...   ...     ...   ...   ...   ...  ...  ...   \n",
       "294  31.9    0.327  56.9    0.530  25.3   0.754  13.4  32.9  22.4  7.3  4.6   \n",
       "295  36.9    0.370  54.8    0.528  23.4   0.729  11.1  35.4  26.8  7.5  5.0   \n",
       "296  30.4    0.348  58.6    0.544  26.1   0.729  11.7  35.7  26.0  7.6  4.4   \n",
       "297  32.1    0.332  55.9    0.528  23.2   0.789  12.0  33.2  25.0  8.3  4.0   \n",
       "298  30.1    0.364  57.5    0.541  24.4   0.793  10.6  33.1  25.9  8.3  4.1   \n",
       "\n",
       "      tov    pf team  year  \n",
       "0    14.1  23.0  TOR  2014  \n",
       "1    12.9  20.9  TOR  2015  \n",
       "2    15.4  21.3  BOS  2014  \n",
       "3    13.8  21.2  BOS  2015  \n",
       "4    13.0  22.1  NYK  2014  \n",
       "..    ...   ...  ...   ...  \n",
       "294  16.2  20.5  HOU  2023  \n",
       "295  16.4  21.2  NOP  2020  \n",
       "296  14.6  18.0  NOP  2021  \n",
       "297  14.1  19.7  NOP  2022  \n",
       "298  14.6  20.5  NOP  2023  \n",
       "\n",
       "[299 rows x 15 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row being feed into the model should have the difference between team stats, whether team A has home court, and the victor of the game\n",
    "\n",
    "# steps -\n",
    "# 0. create train/test split of game results + team/g stats (let's try doing this randomly first, maybe can try by year later)\n",
    "# 1. normalize team/g stats (can try normalizing all the stats together, then maybe group by year later)\n",
    "# 2. create copy of game results df where home team is shuffled, and whether the 1st team in the new team A column is the home team, and create a did_team A win column\n",
    "# 3. create a new df with team A team/g stats - team B team/g stats for that year\n",
    "# 4. create a df joining game results with team shuffled with normalized team/g stats difference\n",
    "# 5. create NN\n",
    "\n",
    "# Try seperating Playoffs from Regular Season - create is regular season ? column in game results df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitor</th>\n",
       "      <th>home</th>\n",
       "      <th>dates</th>\n",
       "      <th>visitor_score</th>\n",
       "      <th>home_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHIBOS20221018</td>\n",
       "      <td>PHI</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20221018</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LALGSW20221018</td>\n",
       "      <td>LAL</td>\n",
       "      <td>GSW</td>\n",
       "      <td>20221018</td>\n",
       "      <td>109</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORLDET20221019</td>\n",
       "      <td>ORL</td>\n",
       "      <td>DET</td>\n",
       "      <td>20221019</td>\n",
       "      <td>109</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASIND20221019</td>\n",
       "      <td>WAS</td>\n",
       "      <td>IND</td>\n",
       "      <td>20221019</td>\n",
       "      <td>114</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOUATL20221019</td>\n",
       "      <td>HOU</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20221019</td>\n",
       "      <td>107</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>MIASAS20140605</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140605</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>MIASAS20140608</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140608</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>SASMIA20140610</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20140610</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>SASMIA20140612</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20140612</td>\n",
       "      <td>107</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>MIASAS20140615</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140615</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id visitor home     dates  visitor_score  home_score\n",
       "0      PHIBOS20221018     PHI  BOS  20221018            117         126\n",
       "1      LALGSW20221018     LAL  GSW  20221018            109         123\n",
       "2      ORLDET20221019     ORL  DET  20221019            109         113\n",
       "3      WASIND20221019     WAS  IND  20221019            114         107\n",
       "4      HOUATL20221019     HOU  ATL  20221019            107         117\n",
       "...               ...     ...  ...       ...            ...         ...\n",
       "12994  MIASAS20140605     MIA  SAS  20140605             95         110\n",
       "12995  MIASAS20140608     MIA  SAS  20140608             98          96\n",
       "12996  SASMIA20140610     SAS  MIA  20140610            111          92\n",
       "12997  SASMIA20140612     SAS  MIA  20140612            107          86\n",
       "12998  MIASAS20140615     MIA  SAS  20140615             87         104\n",
       "\n",
       "[12999 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_results_sql_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_indexes = random.sample(range(len(all_game_results_df)), k = len(all_game_results_df)//2)\n",
    "all_game_results_df.loc[random_indexes,'team_a'] = all_game_results_df.loc[random_indexes,'visitor']\n",
    "all_game_results_df.loc[random_indexes,'team_b'] = all_game_results_df.loc[random_indexes,'home']\n",
    "all_game_results_df.loc[all_game_results_df['team_a'].isna(),'team_a'] = all_game_results_df.loc[all_game_results_df['team_a'].isna(),'home']\n",
    "all_game_results_df.loc[all_game_results_df['team_b'].isna(),'team_b'] = all_game_results_df.loc[all_game_results_df['team_b'].isna(),'visitor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_game_results_df['team_a_is_home'] = (all_game_results_df['team_a'] == all_game_results_df['home']).astype(int)\n",
    "all_game_results_df['team_a_score'] = (all_game_results_df['team_a_is_home'] * all_game_results_df['home_score']) + (([1 - all_game_results_df['team_a_is_home']][0]) * all_game_results_df['visitor_score'])\n",
    "all_game_results_df['team_b_score'] = (all_game_results_df['team_a_is_home'] * all_game_results_df['visitor_score']) + (([1 - all_game_results_df['team_a_is_home']][0]) * all_game_results_df['home_score'])\n",
    "all_game_results_df['team_a_win'] = (all_game_results_df['team_a_score'] > all_game_results_df['team_b_score']).astype(int)\n",
    "all_game_results_df['season_year'] = (all_game_results_df.loc[:,'dates'] // 10000) + ((all_game_results_df.loc[:,'dates'] % 10000) // 100) // 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>visitor</th>\n",
       "      <th>home</th>\n",
       "      <th>dates</th>\n",
       "      <th>visitor_score</th>\n",
       "      <th>home_score</th>\n",
       "      <th>team_a</th>\n",
       "      <th>team_b</th>\n",
       "      <th>team_a_is_home</th>\n",
       "      <th>team_a_score</th>\n",
       "      <th>team_b_score</th>\n",
       "      <th>team_a_win</th>\n",
       "      <th>season_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHIBOS20221018</td>\n",
       "      <td>PHI</td>\n",
       "      <td>BOS</td>\n",
       "      <td>20221018</td>\n",
       "      <td>117</td>\n",
       "      <td>126</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LALGSW20221018</td>\n",
       "      <td>LAL</td>\n",
       "      <td>GSW</td>\n",
       "      <td>20221018</td>\n",
       "      <td>109</td>\n",
       "      <td>123</td>\n",
       "      <td>LAL</td>\n",
       "      <td>GSW</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORLDET20221019</td>\n",
       "      <td>ORL</td>\n",
       "      <td>DET</td>\n",
       "      <td>20221019</td>\n",
       "      <td>109</td>\n",
       "      <td>113</td>\n",
       "      <td>DET</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WASIND20221019</td>\n",
       "      <td>WAS</td>\n",
       "      <td>IND</td>\n",
       "      <td>20221019</td>\n",
       "      <td>114</td>\n",
       "      <td>107</td>\n",
       "      <td>IND</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>107</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOUATL20221019</td>\n",
       "      <td>HOU</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20221019</td>\n",
       "      <td>107</td>\n",
       "      <td>117</td>\n",
       "      <td>ATL</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>MIASAS20140605</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140605</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>MIASAS20140608</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140608</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>SASMIA20140610</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20140610</td>\n",
       "      <td>111</td>\n",
       "      <td>92</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>SASMIA20140612</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>20140612</td>\n",
       "      <td>107</td>\n",
       "      <td>86</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>1</td>\n",
       "      <td>86</td>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>MIASAS20140615</td>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>20140615</td>\n",
       "      <td>87</td>\n",
       "      <td>104</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12999 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id visitor home     dates  visitor_score  home_score  \\\n",
       "0      PHIBOS20221018     PHI  BOS  20221018            117         126   \n",
       "1      LALGSW20221018     LAL  GSW  20221018            109         123   \n",
       "2      ORLDET20221019     ORL  DET  20221019            109         113   \n",
       "3      WASIND20221019     WAS  IND  20221019            114         107   \n",
       "4      HOUATL20221019     HOU  ATL  20221019            107         117   \n",
       "...               ...     ...  ...       ...            ...         ...   \n",
       "12994  MIASAS20140605     MIA  SAS  20140605             95         110   \n",
       "12995  MIASAS20140608     MIA  SAS  20140608             98          96   \n",
       "12996  SASMIA20140610     SAS  MIA  20140610            111          92   \n",
       "12997  SASMIA20140612     SAS  MIA  20140612            107          86   \n",
       "12998  MIASAS20140615     MIA  SAS  20140615             87         104   \n",
       "\n",
       "      team_a team_b  team_a_is_home  team_a_score  team_b_score  team_a_win  \\\n",
       "0        BOS    PHI               1           126           117           1   \n",
       "1        LAL    GSW               0           109           123           0   \n",
       "2        DET    ORL               1           113           109           1   \n",
       "3        IND    WAS               1           107           114           0   \n",
       "4        ATL    HOU               1           117           107           1   \n",
       "...      ...    ...             ...           ...           ...         ...   \n",
       "12994    MIA    SAS               0            95           110           0   \n",
       "12995    SAS    MIA               1            96            98           0   \n",
       "12996    MIA    SAS               1            92           111           0   \n",
       "12997    MIA    SAS               1            86           107           0   \n",
       "12998    SAS    MIA               1           104            87           1   \n",
       "\n",
       "       season_year  \n",
       "0             2023  \n",
       "1             2023  \n",
       "2             2023  \n",
       "3             2023  \n",
       "4             2023  \n",
       "...            ...  \n",
       "12994         2014  \n",
       "12995         2014  \n",
       "12996         2014  \n",
       "12997         2014  \n",
       "12998         2014  \n",
       "\n",
       "[12999 rows x 13 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_game_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.4</td>\n",
       "      <td>0.372</td>\n",
       "      <td>58.5</td>\n",
       "      <td>0.475</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.782</td>\n",
       "      <td>11.4</td>\n",
       "      <td>31.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>14.1</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.1</td>\n",
       "      <td>0.352</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.499</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.787</td>\n",
       "      <td>10.7</td>\n",
       "      <td>30.8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.1</td>\n",
       "      <td>0.333</td>\n",
       "      <td>62.9</td>\n",
       "      <td>0.470</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.777</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>15.4</td>\n",
       "      <td>21.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.6</td>\n",
       "      <td>0.327</td>\n",
       "      <td>63.3</td>\n",
       "      <td>0.488</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.754</td>\n",
       "      <td>11.1</td>\n",
       "      <td>32.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.9</td>\n",
       "      <td>0.372</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.482</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.761</td>\n",
       "      <td>10.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>31.9</td>\n",
       "      <td>0.327</td>\n",
       "      <td>56.9</td>\n",
       "      <td>0.530</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.754</td>\n",
       "      <td>13.4</td>\n",
       "      <td>32.9</td>\n",
       "      <td>22.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>16.2</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>36.9</td>\n",
       "      <td>0.370</td>\n",
       "      <td>54.8</td>\n",
       "      <td>0.528</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.729</td>\n",
       "      <td>11.1</td>\n",
       "      <td>35.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>21.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>30.4</td>\n",
       "      <td>0.348</td>\n",
       "      <td>58.6</td>\n",
       "      <td>0.544</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.729</td>\n",
       "      <td>11.7</td>\n",
       "      <td>35.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>32.1</td>\n",
       "      <td>0.332</td>\n",
       "      <td>55.9</td>\n",
       "      <td>0.528</td>\n",
       "      <td>23.2</td>\n",
       "      <td>0.789</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>30.1</td>\n",
       "      <td>0.364</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.541</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.793</td>\n",
       "      <td>10.6</td>\n",
       "      <td>33.1</td>\n",
       "      <td>25.9</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14.6</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     fg3a  fg3_pct  fg2a  fg2_pct   fta  ft_pct   orb   drb   ast  stl  blk  \\\n",
       "0    23.4    0.372  58.5    0.475  25.1   0.782  11.4  31.1  21.2  7.0  4.2   \n",
       "1    25.1    0.352  58.2    0.499  24.6   0.787  10.7  30.8  20.7  7.5  4.4   \n",
       "2    21.1    0.333  62.9    0.470  20.8   0.777  12.0  30.5  21.0  7.1  4.2   \n",
       "3    24.6    0.327  63.3    0.488  20.5   0.754  11.1  32.7  24.5  8.2  3.6   \n",
       "4    24.9    0.372  57.3    0.482  20.4   0.761  10.6  29.7  20.0  7.7  4.5   \n",
       "..    ...      ...   ...      ...   ...     ...   ...   ...   ...  ...  ...   \n",
       "294  31.9    0.327  56.9    0.530  25.3   0.754  13.4  32.9  22.4  7.3  4.6   \n",
       "295  36.9    0.370  54.8    0.528  23.4   0.729  11.1  35.4  26.8  7.5  5.0   \n",
       "296  30.4    0.348  58.6    0.544  26.1   0.729  11.7  35.7  26.0  7.6  4.4   \n",
       "297  32.1    0.332  55.9    0.528  23.2   0.789  12.0  33.2  25.0  8.3  4.0   \n",
       "298  30.1    0.364  57.5    0.541  24.4   0.793  10.6  33.1  25.9  8.3  4.1   \n",
       "\n",
       "      tov    pf  \n",
       "0    14.1  23.0  \n",
       "1    12.9  20.9  \n",
       "2    15.4  21.3  \n",
       "3    13.8  21.2  \n",
       "4    13.0  22.1  \n",
       "..    ...   ...  \n",
       "294  16.2  20.5  \n",
       "295  16.4  21.2  \n",
       "296  14.6  18.0  \n",
       "297  14.1  19.7  \n",
       "298  14.6  20.5  \n",
       "\n",
       "[299 rows x 13 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df.iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.1</td>\n",
       "      <td>0.352</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.499</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.787</td>\n",
       "      <td>10.7</td>\n",
       "      <td>30.8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.9</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fg3a  fg3_pct  fg2a  fg2_pct   fta  ft_pct   orb   drb   ast  stl  blk  \\\n",
       "1  25.1    0.352  58.2    0.499  24.6   0.787  10.7  30.8  20.7  7.5  4.4   \n",
       "\n",
       "    tov    pf  \n",
       "1  12.9  20.9  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df[(team_per_game_stats_df['team'] == 'TOR') & (team_per_game_stats_df['year'] == 2015)].iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.3</td>\n",
       "      <td>0.346</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.501</td>\n",
       "      <td>23.5</td>\n",
       "      <td>0.733</td>\n",
       "      <td>11.2</td>\n",
       "      <td>31.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fg3a  fg3_pct  fg2a  fg2_pct   fta  ft_pct   orb   drb   ast  stl  blk  \\\n",
       "1  22.3    0.346  60.5    0.501  23.5   0.733  11.2  31.2  22.8  6.9  5.0   \n",
       "\n",
       "    tov    pf  \n",
       "1  14.4  20.3  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opponent_per_game_stats_df[(opponent_per_game_stats_df['team'] == 'TOR') & (opponent_per_game_stats_df['year'] == 2015)].iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.356</td>\n",
       "      <td>64.8</td>\n",
       "      <td>0.461</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.751</td>\n",
       "      <td>12.1</td>\n",
       "      <td>32.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>14.2</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fg3a  fg3_pct  fg2a  fg2_pct   fta  ft_pct   orb   drb   ast  stl  blk  \\\n",
       "10  20.0    0.356  64.8    0.461  22.7   0.751  12.1  32.1  21.2  7.1  3.7   \n",
       "\n",
       "     tov    pf  \n",
       "10  14.2  20.0  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df[(team_per_game_stats_df['team'] == 'CLE') & (team_per_game_stats_df['year'] == 2014)].iloc[:,:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = np.subtract(np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == 'TOR') & (team_per_game_stats_df['year'] == 2014)].iloc[:,:-2]), np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == 'CLE') & (team_per_game_stats_df['year'] == 2014)].iloc[:,:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fg3a', 'fg3_pct', 'fg2a', 'fg2_pct', 'fta', 'ft_pct', 'orb', 'drb',\n",
       "       'ast', 'stl', 'blk', 'tov', 'pf'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_per_game_stats_df.iloc[:,:-2].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.4</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>0.014</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fg3a  fg3_pct  fg2a  fg2_pct  fta  ft_pct  orb  drb  ast  stl  blk  tov  \\\n",
       "0   3.4    0.016  -6.3    0.014  2.4   0.031 -0.7 -1.0  0.0 -0.1  0.5 -0.1   \n",
       "\n",
       "    pf  \n",
       "0  3.0  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data= val, columns= team_per_game_stats_df.iloc[:,:-2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_a</th>\n",
       "      <th>team_b</th>\n",
       "      <th>season_year</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOS</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2023</td>\n",
       "      <td>20221018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LAL</td>\n",
       "      <td>GSW</td>\n",
       "      <td>2023</td>\n",
       "      <td>20221018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DET</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2023</td>\n",
       "      <td>20221019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IND</td>\n",
       "      <td>WAS</td>\n",
       "      <td>2023</td>\n",
       "      <td>20221019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2023</td>\n",
       "      <td>20221019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>2014</td>\n",
       "      <td>20140605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2014</td>\n",
       "      <td>20140608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>2014</td>\n",
       "      <td>20140610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>MIA</td>\n",
       "      <td>SAS</td>\n",
       "      <td>2014</td>\n",
       "      <td>20140612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>SAS</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2014</td>\n",
       "      <td>20140615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11685 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team_a team_b  season_year     dates\n",
       "0        BOS    PHI         2023  20221018\n",
       "1        LAL    GSW         2023  20221018\n",
       "2        DET    ORL         2023  20221019\n",
       "3        IND    WAS         2023  20221019\n",
       "4        ATL    HOU         2023  20221019\n",
       "...      ...    ...          ...       ...\n",
       "12994    MIA    SAS         2014  20140605\n",
       "12995    SAS    MIA         2014  20140608\n",
       "12996    MIA    SAS         2014  20140610\n",
       "12997    MIA    SAS         2014  20140612\n",
       "12998    SAS    MIA         2014  20140615\n",
       "\n",
       "[11685 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_game_results_df.loc[all_game_results_df['season_year'] > 2013, ['team_a', 'team_b', 'season_year', 'dates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_stats(team_a, team_b, season_year) : return np.subtract(np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == team_a) & (team_per_game_stats_df['year'] == season_year)].iloc[:,:-2]), np.array(team_per_game_stats_df[(team_per_game_stats_df['team'] == team_b) & (team_per_game_stats_df['year'] == season_year)].iloc[:,:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(diff_stats('CLE', 'TOR', 2014)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.4  , -0.016,  6.3  , -0.014, -2.4  , -0.031,  0.7  ,  1.   ,\n",
       "         0.   ,  0.1  , -0.5  ,  0.1  , -3.   ]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_stats('CLE', 'TOR', 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_game_df = all_game_results_df.loc[all_game_results_df['season_year'] > 2013, ['team_a', 'team_b', 'season_year', 'dates']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_game_df['team_stats_diff'] = combined_game_df.apply(lambda x: diff_stats(x.team_a, x.team_b, x.season_year), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_game_df[combined_game_df['team_stats_diff'].apply(len) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_game_df2 = combined_game_df[combined_game_df['team_stats_diff'].apply(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_a</th>\n",
       "      <th>team_b</th>\n",
       "      <th>season_year</th>\n",
       "      <th>dates</th>\n",
       "      <th>team_stats_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>ORL</td>\n",
       "      <td>IND</td>\n",
       "      <td>2014</td>\n",
       "      <td>20131029</td>\n",
       "      <td>[[0.6999999999999993, -0.0040000000000000036, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>CHI</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2014</td>\n",
       "      <td>20131029</td>\n",
       "      <td>[[-4.5, -0.016000000000000014, 8.1999999999999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>LAL</td>\n",
       "      <td>LAC</td>\n",
       "      <td>2014</td>\n",
       "      <td>20131029</td>\n",
       "      <td>[[0.8000000000000007, 0.029000000000000026, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>CLE</td>\n",
       "      <td>BRK</td>\n",
       "      <td>2014</td>\n",
       "      <td>20131030</td>\n",
       "      <td>[[-3.3999999999999986, -0.013000000000000012, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>BOS</td>\n",
       "      <td>TOR</td>\n",
       "      <td>2014</td>\n",
       "      <td>20131030</td>\n",
       "      <td>[[-2.299999999999997, -0.03899999999999998, 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023</td>\n",
       "      <td>20230601</td>\n",
       "      <td>[[-3.599999999999998, 0.03500000000000003, 4.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023</td>\n",
       "      <td>20230604</td>\n",
       "      <td>[[3.599999999999998, -0.03500000000000003, -4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>DEN</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2023</td>\n",
       "      <td>20230607</td>\n",
       "      <td>[[-3.599999999999998, 0.03500000000000003, 4.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023</td>\n",
       "      <td>20230609</td>\n",
       "      <td>[[3.599999999999998, -0.03500000000000003, -4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>MIA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2023</td>\n",
       "      <td>20230612</td>\n",
       "      <td>[[3.599999999999998, -0.03500000000000003, -4....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11599 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team_a team_b  season_year     dates  \\\n",
       "1314     ORL    IND         2014  20131029   \n",
       "1315     CHI    MIA         2014  20131029   \n",
       "1316     LAL    LAC         2014  20131029   \n",
       "1317     CLE    BRK         2014  20131030   \n",
       "1318     BOS    TOR         2014  20131030   \n",
       "...      ...    ...          ...       ...   \n",
       "12994    DEN    MIA         2023  20230601   \n",
       "12995    MIA    DEN         2023  20230604   \n",
       "12996    DEN    MIA         2023  20230607   \n",
       "12997    MIA    DEN         2023  20230609   \n",
       "12998    MIA    DEN         2023  20230612   \n",
       "\n",
       "                                         team_stats_diff  \n",
       "1314   [[0.6999999999999993, -0.0040000000000000036, ...  \n",
       "1315   [[-4.5, -0.016000000000000014, 8.1999999999999...  \n",
       "1316   [[0.8000000000000007, 0.029000000000000026, 1....  \n",
       "1317   [[-3.3999999999999986, -0.013000000000000012, ...  \n",
       "1318   [[-2.299999999999997, -0.03899999999999998, 4....  \n",
       "...                                                  ...  \n",
       "12994  [[-3.599999999999998, 0.03500000000000003, 4.7...  \n",
       "12995  [[3.599999999999998, -0.03500000000000003, -4....  \n",
       "12996  [[-3.599999999999998, 0.03500000000000003, 4.7...  \n",
       "12997  [[3.599999999999998, -0.03500000000000003, -4....  \n",
       "12998  [[3.599999999999998, -0.03500000000000003, -4....  \n",
       "\n",
       "[11599 rows x 5 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_game_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(combined_game_df['team_stats_diff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_game_df2.loc[1314:1316,'team_stats_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(data = combined_game_df2.loc[1314:1316,'team_stats_diff'].apply(lambda x: x[0]).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(data = combined_game_df2.loc[1314:1316,'team_stats_diff'].apply(lambda x: x[0]).tolist(), columns=team_per_game_stats_df.iloc[:,:-2].columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_game_df2[team_per_game_stats_df.iloc[:,:-2].columns.tolist()] = combined_game_df2.team_stats_diff.apply(lambda x: x[0]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_game_df2[['team_a_is_home', 'team_a_win']] = all_game_results_df.loc[1314:,['team_a_is_home', 'team_a_win']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fg3a</th>\n",
       "      <th>fg3_pct</th>\n",
       "      <th>fg2a</th>\n",
       "      <th>fg2_pct</th>\n",
       "      <th>fta</th>\n",
       "      <th>ft_pct</th>\n",
       "      <th>orb</th>\n",
       "      <th>drb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>tov</th>\n",
       "      <th>pf</th>\n",
       "      <th>team_a_is_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>1.9</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>-4.5</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.019</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.029</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.047</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>-3.4</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>10.3</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>-2.3</td>\n",
       "      <td>-0.039</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-4.3</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.035</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>3.6</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.035</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.035</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>3.6</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12998</th>\n",
       "      <td>3.6</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.080</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11599 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fg3a  fg3_pct  fg2a  fg2_pct  fta  ft_pct  orb  drb  ast  stl  blk  \\\n",
       "1314    0.7   -0.004   1.9   -0.003 -2.4  -0.016 -0.5 -2.1  0.9  1.0 -1.1   \n",
       "1315   -4.5   -0.016   8.2   -0.102  0.3   0.019  3.8  3.5  0.2 -1.7  0.7   \n",
       "1316    0.8    0.029   1.8   -0.047 -6.7   0.027 -1.4 -0.5 -0.1 -1.1  0.6   \n",
       "1317   -3.4   -0.013  10.3   -0.036 -1.7  -0.002  3.3  2.7  0.3 -1.5 -0.1   \n",
       "1318   -2.3   -0.039   4.4   -0.005 -4.3  -0.005  0.6 -0.6 -0.2  0.1  0.0   \n",
       "...     ...      ...   ...      ...  ...     ...  ...  ...  ...  ...  ...   \n",
       "12994  -3.6    0.035   4.7    0.035 -0.6  -0.080  0.4  2.0  5.1 -0.5  1.5   \n",
       "12995   3.6   -0.035  -4.7   -0.035  0.6   0.080 -0.4 -2.0 -5.1  0.5 -1.5   \n",
       "12996  -3.6    0.035   4.7    0.035 -0.6  -0.080  0.4  2.0  5.1 -0.5  1.5   \n",
       "12997   3.6   -0.035  -4.7   -0.035  0.6   0.080 -0.4 -2.0 -5.1  0.5 -1.5   \n",
       "12998   3.6   -0.035  -4.7   -0.035  0.6   0.080 -0.4 -2.0 -5.1  0.5 -1.5   \n",
       "\n",
       "       tov   pf  team_a_is_home  \n",
       "1314  -0.2  0.1               0  \n",
       "1315   0.1 -0.4               0  \n",
       "1316   1.2 -1.7               1  \n",
       "1317  -0.3 -1.7               1  \n",
       "1318   1.3 -1.7               0  \n",
       "...    ...  ...             ...  \n",
       "12994  1.0  0.1               1  \n",
       "12995 -1.0 -0.1               0  \n",
       "12996  1.0  0.1               0  \n",
       "12997 -1.0 -0.1               1  \n",
       "12998 -1.0 -0.1               0  \n",
       "\n",
       "[11599 rows x 14 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_game_df2[['fg3a', 'fg3_pct', 'fg2a', 'fg2_pct', 'fta', 'ft_pct', 'orb', 'drb', 'ast', 'stl', 'blk', 'tov', 'pf', 'team_a_is_home']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = combined_game_df2[['fg3a', 'fg3_pct', 'fg2a', 'fg2_pct', 'fta', 'ft_pct', 'orb', 'drb', 'ast', 'stl', 'blk', 'tov', 'pf', 'team_a_is_home']]\n",
    "y = combined_game_df2['team_a_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dense, Activation,Dropout\n",
      "File \u001b[0;32m~/Documents/GitHub/nba_stats_tracking/.venv/lib/python3.9/site-packages/tensorflow/__init__.py:45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[1;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[0;32m~/Documents/GitHub/nba_stats_tracking/.venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__ namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m autograph\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch\n",
      "File \u001b[0;32m~/Documents/GitHub/nba_stats_tracking/.venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.autograph namespace\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mag_ctx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_status_ctx \u001b[38;5;66;03m# line: 34\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_convert \u001b[38;5;66;03m# line: 493\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/nba_stats_tracking/.venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ag_logging\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tf_export\n\u001b[1;32m     25\u001b[0m stacks \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mlocal()\n",
      "File \u001b[0;32m~/Documents/GitHub/nba_stats_tracking/.venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Utility module that contains APIs usable in the generated code.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontext_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m control_dependency_on_returns\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m alias_tensors\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_list\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dynamic_list_append\n",
      "File \u001b[0;32m~/Documents/GitHub/nba_stats_tracking/.venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Various context managers.\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tensor_array_ops\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcontrol_dependency_on_returns\u001b[39m(return_value):\n",
      "File \u001b[0;32m~/Documents/GitHub/nba_stats_tracking/.venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906\u001b[0m\n\u001b[1;32m   5900\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[1;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   5904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_to_proto_function\u001b[39m(\n\u001b[1;32m   5905\u001b[0m     collection_name,\n\u001b[0;32m-> 5906\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCallable\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m   5907\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the to_proto function for collection_name.\"\"\"\u001b[39;00m\n\u001b[1;32m   5908\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:262\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:339\u001b[0m, in \u001b[0;36m_SpecialForm.__getitem__\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;129m@_tp_cache\u001b[39m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters):\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:463\u001b[0m, in \u001b[0;36mOptional\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Optional type.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03mOptional[X] is equivalent to Union[X, None].\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    462\u001b[0m arg \u001b[38;5;241m=\u001b[39m _type_check(parameters, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires a single type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 463\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mUnion\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:262\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:339\u001b[0m, in \u001b[0;36m_SpecialForm.__getitem__\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;129m@_tp_cache\u001b[39m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, parameters):\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:451\u001b[0m, in \u001b[0;36mUnion\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    449\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnion[arg, ...]: each arg must be a type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(_type_check(p, msg) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters)\n\u001b[0;32m--> 451\u001b[0m parameters \u001b[38;5;241m=\u001b[39m \u001b[43m_remove_dups_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parameters) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parameters[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:231\u001b[0m, in \u001b[0;36m_remove_dups_flatten\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m         params\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[0;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[43m_deduplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/typing.py:205\u001b[0m, in \u001b[0;36m_deduplicate\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_deduplicate\u001b[39m(params):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;66;03m# Weed out strict duplicates, preserving the first of each occurrence.\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m     all_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(all_params) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(params):\n\u001b[1;32m    207\u001b[0m         new_params \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8699, 14)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 20:49:17.520905: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "model.add(Dense(units=14,activation='relu'))\n",
    "\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6818 - val_loss: 0.6704\n",
      "Epoch 2/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6563 - val_loss: 0.6481\n",
      "Epoch 3/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6363 - val_loss: 0.6398\n",
      "Epoch 4/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6291 - val_loss: 0.6370\n",
      "Epoch 5/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6252 - val_loss: 0.6372\n",
      "Epoch 6/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6225 - val_loss: 0.6344\n",
      "Epoch 7/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6205 - val_loss: 0.6331\n",
      "Epoch 8/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6186 - val_loss: 0.6350\n",
      "Epoch 9/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6172 - val_loss: 0.6305\n",
      "Epoch 10/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6155 - val_loss: 0.6301\n",
      "Epoch 11/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6149 - val_loss: 0.6406\n",
      "Epoch 12/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6134 - val_loss: 0.6285\n",
      "Epoch 13/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6259\n",
      "Epoch 14/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6107 - val_loss: 0.6251\n",
      "Epoch 15/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6258\n",
      "Epoch 16/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6093 - val_loss: 0.6270\n",
      "Epoch 17/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6094 - val_loss: 0.6235\n",
      "Epoch 18/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6086 - val_loss: 0.6232\n",
      "Epoch 19/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6085 - val_loss: 0.6230\n",
      "Epoch 20/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6067 - val_loss: 0.6240\n",
      "Epoch 21/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6071 - val_loss: 0.6229\n",
      "Epoch 22/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6057 - val_loss: 0.6231\n",
      "Epoch 23/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6062 - val_loss: 0.6237\n",
      "Epoch 24/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6061 - val_loss: 0.6215\n",
      "Epoch 25/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6044 - val_loss: 0.6240\n",
      "Epoch 26/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6049 - val_loss: 0.6258\n",
      "Epoch 27/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6048 - val_loss: 0.6236\n",
      "Epoch 28/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 0.6230\n",
      "Epoch 29/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.6224\n",
      "Epoch 30/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6046 - val_loss: 0.6214\n",
      "Epoch 31/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6043 - val_loss: 0.6240\n",
      "Epoch 32/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.6228\n",
      "Epoch 33/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6041 - val_loss: 0.6258\n",
      "Epoch 34/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6042 - val_loss: 0.6205\n",
      "Epoch 35/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.6223\n",
      "Epoch 36/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6022 - val_loss: 0.6249\n",
      "Epoch 37/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6034 - val_loss: 0.6218\n",
      "Epoch 38/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6036 - val_loss: 0.6201\n",
      "Epoch 39/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6029 - val_loss: 0.6200\n",
      "Epoch 40/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6033 - val_loss: 0.6247\n",
      "Epoch 41/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6029 - val_loss: 0.6207\n",
      "Epoch 42/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6028 - val_loss: 0.6265\n",
      "Epoch 43/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6030 - val_loss: 0.6216\n",
      "Epoch 44/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6041 - val_loss: 0.6209\n",
      "Epoch 45/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6034 - val_loss: 0.6202\n",
      "Epoch 46/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6021 - val_loss: 0.6214\n",
      "Epoch 47/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6019 - val_loss: 0.6286\n",
      "Epoch 48/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6024 - val_loss: 0.6252\n",
      "Epoch 49/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6040 - val_loss: 0.6259\n",
      "Epoch 50/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6025 - val_loss: 0.6209\n",
      "Epoch 51/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6024 - val_loss: 0.6217\n",
      "Epoch 52/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6036 - val_loss: 0.6198\n",
      "Epoch 53/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.6216\n",
      "Epoch 54/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6021 - val_loss: 0.6212\n",
      "Epoch 55/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6019 - val_loss: 0.6211\n",
      "Epoch 56/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6022 - val_loss: 0.6222\n",
      "Epoch 57/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.6207\n",
      "Epoch 58/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6018 - val_loss: 0.6232\n",
      "Epoch 59/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6227\n",
      "Epoch 60/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.6206\n",
      "Epoch 61/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6018 - val_loss: 0.6239\n",
      "Epoch 62/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6213\n",
      "Epoch 63/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6222\n",
      "Epoch 64/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6021 - val_loss: 0.6229\n",
      "Epoch 65/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 0.6202\n",
      "Epoch 66/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6018 - val_loss: 0.6220\n",
      "Epoch 67/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.6203\n",
      "Epoch 68/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6016 - val_loss: 0.6219\n",
      "Epoch 69/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6320\n",
      "Epoch 70/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6021 - val_loss: 0.6204\n",
      "Epoch 71/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6209\n",
      "Epoch 72/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6218\n",
      "Epoch 73/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6241\n",
      "Epoch 74/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6007 - val_loss: 0.6228\n",
      "Epoch 75/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6019 - val_loss: 0.6273\n",
      "Epoch 76/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6016 - val_loss: 0.6225\n",
      "Epoch 77/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6210\n",
      "Epoch 78/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.6274\n",
      "Epoch 79/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6016 - val_loss: 0.6220\n",
      "Epoch 80/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6016 - val_loss: 0.6206\n",
      "Epoch 81/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6246\n",
      "Epoch 82/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6016 - val_loss: 0.6217\n",
      "Epoch 83/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6008 - val_loss: 0.6246\n",
      "Epoch 84/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.6254\n",
      "Epoch 85/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6227\n",
      "Epoch 86/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6204\n",
      "Epoch 87/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 0.6215\n",
      "Epoch 88/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.6207\n",
      "Epoch 89/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6215\n",
      "Epoch 90/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6219\n",
      "Epoch 91/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.6236\n",
      "Epoch 92/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6206\n",
      "Epoch 93/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6017 - val_loss: 0.6215\n",
      "Epoch 94/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6019 - val_loss: 0.6238\n",
      "Epoch 95/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.6209\n",
      "Epoch 96/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6003 - val_loss: 0.6216\n",
      "Epoch 97/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6203\n",
      "Epoch 98/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6010 - val_loss: 0.6205\n",
      "Epoch 99/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6221\n",
      "Epoch 100/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6264\n",
      "Epoch 101/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6007 - val_loss: 0.6206\n",
      "Epoch 102/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6212\n",
      "Epoch 103/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6223\n",
      "Epoch 104/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.6217\n",
      "Epoch 105/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6208\n",
      "Epoch 106/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6352\n",
      "Epoch 107/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6018 - val_loss: 0.6204\n",
      "Epoch 108/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6209\n",
      "Epoch 109/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6208\n",
      "Epoch 110/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6207\n",
      "Epoch 111/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6216\n",
      "Epoch 112/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6221\n",
      "Epoch 113/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6008 - val_loss: 0.6222\n",
      "Epoch 114/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6008 - val_loss: 0.6209\n",
      "Epoch 115/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6210\n",
      "Epoch 116/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6001 - val_loss: 0.6220\n",
      "Epoch 117/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6342\n",
      "Epoch 118/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6206\n",
      "Epoch 119/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6237\n",
      "Epoch 120/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6211\n",
      "Epoch 121/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6220\n",
      "Epoch 122/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6299\n",
      "Epoch 123/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6208\n",
      "Epoch 124/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6215\n",
      "Epoch 125/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6231\n",
      "Epoch 126/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6266\n",
      "Epoch 127/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6001 - val_loss: 0.6252\n",
      "Epoch 128/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6209\n",
      "Epoch 129/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6214\n",
      "Epoch 130/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6223\n",
      "Epoch 131/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.6215\n",
      "Epoch 132/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.6208\n",
      "Epoch 133/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6305\n",
      "Epoch 134/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6231\n",
      "Epoch 135/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 0.6207\n",
      "Epoch 136/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6205\n",
      "Epoch 137/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6219\n",
      "Epoch 138/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6296\n",
      "Epoch 139/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6001 - val_loss: 0.6231\n",
      "Epoch 140/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6216\n",
      "Epoch 141/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6205\n",
      "Epoch 142/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6215\n",
      "Epoch 143/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.5995 - val_loss: 0.6221\n",
      "Epoch 144/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6220\n",
      "Epoch 145/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6222\n",
      "Epoch 146/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6212\n",
      "Epoch 147/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6207\n",
      "Epoch 148/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6214\n",
      "Epoch 149/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6226\n",
      "Epoch 150/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6259\n",
      "Epoch 151/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6209\n",
      "Epoch 152/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6228\n",
      "Epoch 153/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6007 - val_loss: 0.6214\n",
      "Epoch 154/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6004 - val_loss: 0.6243\n",
      "Epoch 155/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6214\n",
      "Epoch 156/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6208\n",
      "Epoch 157/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6208\n",
      "Epoch 158/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6209\n",
      "Epoch 159/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5994 - val_loss: 0.6206\n",
      "Epoch 160/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6243\n",
      "Epoch 161/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6210\n",
      "Epoch 162/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.6239\n",
      "Epoch 163/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.6322\n",
      "Epoch 164/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6234\n",
      "Epoch 165/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6312\n",
      "Epoch 166/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6204\n",
      "Epoch 167/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5994 - val_loss: 0.6238\n",
      "Epoch 168/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6239\n",
      "Epoch 169/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.6210\n",
      "Epoch 170/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6213\n",
      "Epoch 171/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6208\n",
      "Epoch 172/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6230\n",
      "Epoch 173/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6219\n",
      "Epoch 174/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6229\n",
      "Epoch 175/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6219\n",
      "Epoch 176/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6283\n",
      "Epoch 177/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6209\n",
      "Epoch 178/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6211\n",
      "Epoch 179/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6236\n",
      "Epoch 180/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6208\n",
      "Epoch 181/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6205\n",
      "Epoch 182/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.6222\n",
      "Epoch 183/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6238\n",
      "Epoch 184/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6236\n",
      "Epoch 185/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6225\n",
      "Epoch 186/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6278\n",
      "Epoch 187/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6006 - val_loss: 0.6211\n",
      "Epoch 188/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6469\n",
      "Epoch 189/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6219\n",
      "Epoch 190/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6284\n",
      "Epoch 191/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6014 - val_loss: 0.6207\n",
      "Epoch 192/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6211\n",
      "Epoch 193/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6241\n",
      "Epoch 194/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6287\n",
      "Epoch 195/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5994 - val_loss: 0.6210\n",
      "Epoch 196/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6299\n",
      "Epoch 197/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6213\n",
      "Epoch 198/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6221\n",
      "Epoch 199/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6258\n",
      "Epoch 200/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6219\n",
      "Epoch 201/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.6238\n",
      "Epoch 202/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6228\n",
      "Epoch 203/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6212\n",
      "Epoch 204/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5994 - val_loss: 0.6209\n",
      "Epoch 205/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5990 - val_loss: 0.6223\n",
      "Epoch 206/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5998 - val_loss: 0.6214\n",
      "Epoch 207/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6221\n",
      "Epoch 208/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6240\n",
      "Epoch 209/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6210\n",
      "Epoch 210/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.6000 - val_loss: 0.6216\n",
      "Epoch 211/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6209\n",
      "Epoch 212/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6232\n",
      "Epoch 213/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6220\n",
      "Epoch 214/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5995 - val_loss: 0.6213\n",
      "Epoch 215/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.5991 - val_loss: 0.6212\n",
      "Epoch 216/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6214\n",
      "Epoch 217/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6210\n",
      "Epoch 218/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6255\n",
      "Epoch 219/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6242\n",
      "Epoch 220/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.5992 - val_loss: 0.6215\n",
      "Epoch 221/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5986 - val_loss: 0.6213\n",
      "Epoch 222/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6237\n",
      "Epoch 223/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6220\n",
      "Epoch 224/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6209\n",
      "Epoch 225/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6222\n",
      "Epoch 226/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6267\n",
      "Epoch 227/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6227\n",
      "Epoch 228/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6237\n",
      "Epoch 229/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6210\n",
      "Epoch 230/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6227\n",
      "Epoch 231/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6263\n",
      "Epoch 232/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6221\n",
      "Epoch 233/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5996 - val_loss: 0.6301\n",
      "Epoch 234/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6276\n",
      "Epoch 235/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6215\n",
      "Epoch 236/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6224\n",
      "Epoch 237/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6297\n",
      "Epoch 238/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6237\n",
      "Epoch 239/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5991 - val_loss: 0.6233\n",
      "Epoch 240/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6219\n",
      "Epoch 241/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6214\n",
      "Epoch 242/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6219\n",
      "Epoch 243/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.5988 - val_loss: 0.6216\n",
      "Epoch 244/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6224\n",
      "Epoch 245/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6210\n",
      "Epoch 246/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6215\n",
      "Epoch 247/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6226\n",
      "Epoch 248/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6216\n",
      "Epoch 249/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6265\n",
      "Epoch 250/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6210\n",
      "Epoch 251/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5981 - val_loss: 0.6213\n",
      "Epoch 252/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6210\n",
      "Epoch 253/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6215\n",
      "Epoch 254/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6225\n",
      "Epoch 255/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6225\n",
      "Epoch 256/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6215\n",
      "Epoch 257/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6221\n",
      "Epoch 258/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6220\n",
      "Epoch 259/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6212\n",
      "Epoch 260/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6237\n",
      "Epoch 261/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6280\n",
      "Epoch 262/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6232\n",
      "Epoch 263/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6241\n",
      "Epoch 264/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6216\n",
      "Epoch 265/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6334\n",
      "Epoch 266/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6220\n",
      "Epoch 267/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6211\n",
      "Epoch 268/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6215\n",
      "Epoch 269/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6215\n",
      "Epoch 270/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6220\n",
      "Epoch 271/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6219\n",
      "Epoch 272/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6216\n",
      "Epoch 273/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6261\n",
      "Epoch 274/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5995 - val_loss: 0.6217\n",
      "Epoch 275/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6263\n",
      "Epoch 276/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6228\n",
      "Epoch 277/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6246\n",
      "Epoch 278/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6231\n",
      "Epoch 279/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6278\n",
      "Epoch 280/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6232\n",
      "Epoch 281/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6239\n",
      "Epoch 282/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6222\n",
      "Epoch 283/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6222\n",
      "Epoch 284/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6250\n",
      "Epoch 285/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6243\n",
      "Epoch 286/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6222\n",
      "Epoch 287/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6224\n",
      "Epoch 288/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6276\n",
      "Epoch 289/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6215\n",
      "Epoch 290/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6278\n",
      "Epoch 291/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6227\n",
      "Epoch 292/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6231\n",
      "Epoch 293/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6227\n",
      "Epoch 294/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6252\n",
      "Epoch 295/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6291\n",
      "Epoch 296/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6222\n",
      "Epoch 297/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6219\n",
      "Epoch 298/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6219\n",
      "Epoch 299/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6403\n",
      "Epoch 300/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6226\n",
      "Epoch 301/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6218\n",
      "Epoch 302/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6285\n",
      "Epoch 303/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6257\n",
      "Epoch 304/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6224\n",
      "Epoch 305/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6215\n",
      "Epoch 306/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6222\n",
      "Epoch 307/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6217\n",
      "Epoch 308/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6220\n",
      "Epoch 309/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6228\n",
      "Epoch 310/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6238\n",
      "Epoch 311/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6232\n",
      "Epoch 312/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6254\n",
      "Epoch 313/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6222\n",
      "Epoch 314/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6219\n",
      "Epoch 315/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6232\n",
      "Epoch 316/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6235\n",
      "Epoch 317/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6220\n",
      "Epoch 318/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5986 - val_loss: 0.6223\n",
      "Epoch 319/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6224\n",
      "Epoch 320/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6230\n",
      "Epoch 321/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6220\n",
      "Epoch 322/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6219\n",
      "Epoch 323/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6216\n",
      "Epoch 324/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6232\n",
      "Epoch 325/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5994 - val_loss: 0.6218\n",
      "Epoch 326/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6224\n",
      "Epoch 327/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6217\n",
      "Epoch 328/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5972 - val_loss: 0.6229\n",
      "Epoch 329/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6239\n",
      "Epoch 330/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6231\n",
      "Epoch 331/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6220\n",
      "Epoch 332/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6239\n",
      "Epoch 333/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6230\n",
      "Epoch 334/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.6221\n",
      "Epoch 335/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6222\n",
      "Epoch 336/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6219\n",
      "Epoch 337/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6257\n",
      "Epoch 338/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5997 - val_loss: 0.6230\n",
      "Epoch 339/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6218\n",
      "Epoch 340/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.5982 - val_loss: 0.6226\n",
      "Epoch 341/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.6217\n",
      "Epoch 342/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6229\n",
      "Epoch 343/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5988 - val_loss: 0.6215\n",
      "Epoch 344/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6241\n",
      "Epoch 345/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6237\n",
      "Epoch 346/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6218\n",
      "Epoch 347/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6224\n",
      "Epoch 348/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6256\n",
      "Epoch 349/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5987 - val_loss: 0.6217\n",
      "Epoch 350/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5990 - val_loss: 0.6218\n",
      "Epoch 351/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6217\n",
      "Epoch 352/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.6269\n",
      "Epoch 353/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5998 - val_loss: 0.6221\n",
      "Epoch 354/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6226\n",
      "Epoch 355/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6222\n",
      "Epoch 356/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5981 - val_loss: 0.6224\n",
      "Epoch 357/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6246\n",
      "Epoch 358/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6246\n",
      "Epoch 359/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6222\n",
      "Epoch 360/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5991 - val_loss: 0.6227\n",
      "Epoch 361/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5989 - val_loss: 0.6237\n",
      "Epoch 362/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6218\n",
      "Epoch 363/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6237\n",
      "Epoch 364/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6218\n",
      "Epoch 365/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6266\n",
      "Epoch 366/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6224\n",
      "Epoch 367/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6272\n",
      "Epoch 368/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6218\n",
      "Epoch 369/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6231\n",
      "Epoch 370/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6216\n",
      "Epoch 371/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6240\n",
      "Epoch 372/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6233\n",
      "Epoch 373/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6225\n",
      "Epoch 374/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6285\n",
      "Epoch 375/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6260\n",
      "Epoch 376/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6240\n",
      "Epoch 377/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6232\n",
      "Epoch 378/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6222\n",
      "Epoch 379/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6238\n",
      "Epoch 380/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6218\n",
      "Epoch 381/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6227\n",
      "Epoch 382/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6224\n",
      "Epoch 383/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6354\n",
      "Epoch 384/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6224\n",
      "Epoch 385/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6219\n",
      "Epoch 386/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6217\n",
      "Epoch 387/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.6219\n",
      "Epoch 388/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.6230\n",
      "Epoch 389/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6262\n",
      "Epoch 390/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6266\n",
      "Epoch 391/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6239\n",
      "Epoch 392/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6244\n",
      "Epoch 393/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6230\n",
      "Epoch 394/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6227\n",
      "Epoch 395/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6227\n",
      "Epoch 396/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6317\n",
      "Epoch 397/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6230\n",
      "Epoch 398/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6224\n",
      "Epoch 399/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6223\n",
      "Epoch 400/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6319\n",
      "Epoch 401/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6221\n",
      "Epoch 402/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6223\n",
      "Epoch 403/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6260\n",
      "Epoch 404/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6219\n",
      "Epoch 405/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6220\n",
      "Epoch 406/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6227\n",
      "Epoch 407/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6224\n",
      "Epoch 408/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6273\n",
      "Epoch 409/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6253\n",
      "Epoch 410/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6231\n",
      "Epoch 411/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6265\n",
      "Epoch 412/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6235\n",
      "Epoch 413/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6225\n",
      "Epoch 414/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6226\n",
      "Epoch 415/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6247\n",
      "Epoch 416/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6225\n",
      "Epoch 417/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.6233\n",
      "Epoch 418/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6234\n",
      "Epoch 419/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6231\n",
      "Epoch 420/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6219\n",
      "Epoch 421/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6252\n",
      "Epoch 422/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6265\n",
      "Epoch 423/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6220\n",
      "Epoch 424/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6231\n",
      "Epoch 425/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6228\n",
      "Epoch 426/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6222\n",
      "Epoch 427/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6241\n",
      "Epoch 428/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6321\n",
      "Epoch 429/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.6224\n",
      "Epoch 430/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6225\n",
      "Epoch 431/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6223\n",
      "Epoch 432/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6227\n",
      "Epoch 433/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6308\n",
      "Epoch 434/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6234\n",
      "Epoch 435/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6227\n",
      "Epoch 436/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6238\n",
      "Epoch 437/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6251\n",
      "Epoch 438/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6244\n",
      "Epoch 439/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6245\n",
      "Epoch 440/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6229\n",
      "Epoch 441/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.6232\n",
      "Epoch 442/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6221\n",
      "Epoch 443/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6222\n",
      "Epoch 444/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6231\n",
      "Epoch 445/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6220\n",
      "Epoch 446/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6233\n",
      "Epoch 447/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6257\n",
      "Epoch 448/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6223\n",
      "Epoch 449/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6224\n",
      "Epoch 450/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6246\n",
      "Epoch 451/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6224\n",
      "Epoch 452/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6258\n",
      "Epoch 453/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6222\n",
      "Epoch 454/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6219\n",
      "Epoch 455/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6224\n",
      "Epoch 456/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.6231\n",
      "Epoch 457/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.6248\n",
      "Epoch 458/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6275\n",
      "Epoch 459/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6251\n",
      "Epoch 460/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6233\n",
      "Epoch 461/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6224\n",
      "Epoch 462/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.6232\n",
      "Epoch 463/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6236\n",
      "Epoch 464/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6234\n",
      "Epoch 465/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6222\n",
      "Epoch 466/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6228\n",
      "Epoch 467/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6224\n",
      "Epoch 468/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6292\n",
      "Epoch 469/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6223\n",
      "Epoch 470/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6259\n",
      "Epoch 471/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6233\n",
      "Epoch 472/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6234\n",
      "Epoch 473/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6249\n",
      "Epoch 474/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6227\n",
      "Epoch 475/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6228\n",
      "Epoch 476/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6241\n",
      "Epoch 477/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6272\n",
      "Epoch 478/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6231\n",
      "Epoch 479/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6259\n",
      "Epoch 480/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.6228\n",
      "Epoch 481/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6226\n",
      "Epoch 482/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6224\n",
      "Epoch 483/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6246\n",
      "Epoch 484/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6274\n",
      "Epoch 485/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6259\n",
      "Epoch 486/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6267\n",
      "Epoch 487/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6224\n",
      "Epoch 488/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6242\n",
      "Epoch 489/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6271\n",
      "Epoch 490/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6222\n",
      "Epoch 491/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6237\n",
      "Epoch 492/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6223\n",
      "Epoch 493/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6240\n",
      "Epoch 494/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6263\n",
      "Epoch 495/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6231\n",
      "Epoch 496/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.6218\n",
      "Epoch 497/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6232\n",
      "Epoch 498/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5958 - val_loss: 0.6404\n",
      "Epoch 499/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5983 - val_loss: 0.6223\n",
      "Epoch 500/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6236\n",
      "Epoch 501/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6243\n",
      "Epoch 502/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6235\n",
      "Epoch 503/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6222\n",
      "Epoch 504/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6223\n",
      "Epoch 505/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6219\n",
      "Epoch 506/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6234\n",
      "Epoch 507/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6222\n",
      "Epoch 508/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5978 - val_loss: 0.6228\n",
      "Epoch 509/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6256\n",
      "Epoch 510/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6238\n",
      "Epoch 511/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6229\n",
      "Epoch 512/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6241\n",
      "Epoch 513/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6234\n",
      "Epoch 514/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6235\n",
      "Epoch 515/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6231\n",
      "Epoch 516/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.6231\n",
      "Epoch 517/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6258\n",
      "Epoch 518/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6227\n",
      "Epoch 519/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6246\n",
      "Epoch 520/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.6225\n",
      "Epoch 521/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6220\n",
      "Epoch 522/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6225\n",
      "Epoch 523/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6246\n",
      "Epoch 524/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5970 - val_loss: 0.6277\n",
      "Epoch 525/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6227\n",
      "Epoch 526/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6262\n",
      "Epoch 527/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6228\n",
      "Epoch 528/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5960 - val_loss: 0.6225\n",
      "Epoch 529/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6259\n",
      "Epoch 530/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6235\n",
      "Epoch 531/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6228\n",
      "Epoch 532/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6250\n",
      "Epoch 533/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6265\n",
      "Epoch 534/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6255\n",
      "Epoch 535/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6263\n",
      "Epoch 536/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5968 - val_loss: 0.6223\n",
      "Epoch 537/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6224\n",
      "Epoch 538/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6273\n",
      "Epoch 539/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5957 - val_loss: 0.6229\n",
      "Epoch 540/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6246\n",
      "Epoch 541/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6230\n",
      "Epoch 542/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5956 - val_loss: 0.6234\n",
      "Epoch 543/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5960 - val_loss: 0.6292\n",
      "Epoch 544/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6278\n",
      "Epoch 545/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6231\n",
      "Epoch 546/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6234\n",
      "Epoch 547/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5958 - val_loss: 0.6247\n",
      "Epoch 548/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5960 - val_loss: 0.6247\n",
      "Epoch 549/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6222\n",
      "Epoch 550/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6238\n",
      "Epoch 551/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6225\n",
      "Epoch 552/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.6248\n",
      "Epoch 553/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5958 - val_loss: 0.6225\n",
      "Epoch 554/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6273\n",
      "Epoch 555/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6227\n",
      "Epoch 556/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5960 - val_loss: 0.6232\n",
      "Epoch 557/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.6232\n",
      "Epoch 558/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6316\n",
      "Epoch 559/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5972 - val_loss: 0.6229\n",
      "Epoch 560/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5961 - val_loss: 0.6234\n",
      "Epoch 561/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6242\n",
      "Epoch 562/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6230\n",
      "Epoch 563/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6227\n",
      "Epoch 564/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6229\n",
      "Epoch 565/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.6253\n",
      "Epoch 566/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6251\n",
      "Epoch 567/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5958 - val_loss: 0.6245\n",
      "Epoch 568/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6225\n",
      "Epoch 569/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6242\n",
      "Epoch 570/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6230\n",
      "Epoch 571/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6234\n",
      "Epoch 572/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6247\n",
      "Epoch 573/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6238\n",
      "Epoch 574/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6240\n",
      "Epoch 575/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5955 - val_loss: 0.6227\n",
      "Epoch 576/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5960 - val_loss: 0.6309\n",
      "Epoch 577/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5964 - val_loss: 0.6248\n",
      "Epoch 578/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5956 - val_loss: 0.6236\n",
      "Epoch 579/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6229\n",
      "Epoch 580/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6241\n",
      "Epoch 581/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5955 - val_loss: 0.6235\n",
      "Epoch 582/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6242\n",
      "Epoch 583/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6227\n",
      "Epoch 584/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5952 - val_loss: 0.6261\n",
      "Epoch 585/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5965 - val_loss: 0.6229\n",
      "Epoch 586/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5956 - val_loss: 0.6254\n",
      "Epoch 587/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5961 - val_loss: 0.6236\n",
      "Epoch 588/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5973 - val_loss: 0.6236\n",
      "Epoch 589/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6277\n",
      "Epoch 590/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6240\n",
      "Epoch 591/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5961 - val_loss: 0.6235\n",
      "Epoch 592/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5960 - val_loss: 0.6241\n",
      "Epoch 593/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.6240\n",
      "Epoch 594/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5971 - val_loss: 0.6229\n",
      "Epoch 595/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6241\n",
      "Epoch 596/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.6238\n",
      "Epoch 597/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6245\n",
      "Epoch 598/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6238\n",
      "Epoch 599/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5959 - val_loss: 0.6246\n",
      "Epoch 600/600\n",
      "272/272 [==============================] - 0s 1ms/step - loss: 0.5956 - val_loss: 0.6249\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faeb685c1c0>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network\n",
    "# https://datascience.stackexchange.com/questions/18414/are-there-any-rules-for-choosing-the-size-of-a-mini-batch\n",
    "\n",
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 956us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62      1440\n",
      "           1       0.64      0.71      0.67      1460\n",
      "\n",
      "    accuracy                           0.65      2900\n",
      "   macro avg       0.65      0.65      0.65      2900\n",
      "weighted avg       0.65      0.65      0.65      2900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.5959 - val_loss: 0.6228\n",
      "Epoch 2/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 0.6227\n",
      "Epoch 3/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5965 - val_loss: 0.6244\n",
      "Epoch 4/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5959 - val_loss: 0.6228\n",
      "Epoch 5/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5952 - val_loss: 0.6273\n",
      "Epoch 6/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 0.6240\n",
      "Epoch 7/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5957 - val_loss: 0.6271\n",
      "Epoch 8/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 0.6267\n",
      "Epoch 9/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6234\n",
      "Epoch 10/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5964 - val_loss: 0.6256\n",
      "Epoch 11/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6270\n",
      "Epoch 12/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 0.6255\n",
      "Epoch 13/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5962 - val_loss: 0.6235\n",
      "Epoch 14/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5958 - val_loss: 0.6235\n",
      "Epoch 15/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6238\n",
      "Epoch 16/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5950 - val_loss: 0.6279\n",
      "Epoch 17/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.5957 - val_loss: 0.6246\n",
      "Epoch 18/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5964 - val_loss: 0.6261\n",
      "Epoch 19/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6244\n",
      "Epoch 20/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5956 - val_loss: 0.6236\n",
      "Epoch 21/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5957 - val_loss: 0.6241\n",
      "Epoch 22/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5954 - val_loss: 0.6240\n",
      "Epoch 23/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5958 - val_loss: 0.6242\n",
      "Epoch 24/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5966 - val_loss: 0.6252\n",
      "Epoch 25/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5952 - val_loss: 0.6249\n",
      "Epoch 26/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5951 - val_loss: 0.6243\n",
      "Epoch 27/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.5960 - val_loss: 0.6249\n",
      "Epoch 27: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faeb6a340a0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62      1440\n",
      "           1       0.64      0.71      0.67      1460\n",
      "\n",
      "    accuracy                           0.65      2900\n",
      "   macro avg       0.65      0.65      0.65      2900\n",
      "weighted avg       0.65      0.65      0.65      2900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=14,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=7,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.7012 - val_loss: 0.6923\n",
      "Epoch 2/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6924 - val_loss: 0.6907\n",
      "Epoch 3/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6891 - val_loss: 0.6865\n",
      "Epoch 4/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6867 - val_loss: 0.6835\n",
      "Epoch 5/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6837 - val_loss: 0.6805\n",
      "Epoch 6/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6826 - val_loss: 0.6781\n",
      "Epoch 7/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6795 - val_loss: 0.6755\n",
      "Epoch 8/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6770 - val_loss: 0.6730\n",
      "Epoch 9/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6699 - val_loss: 0.6658\n",
      "Epoch 10/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6691 - val_loss: 0.6687\n",
      "Epoch 11/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6680 - val_loss: 0.6621\n",
      "Epoch 12/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6665 - val_loss: 0.6579\n",
      "Epoch 13/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6646 - val_loss: 0.6547\n",
      "Epoch 14/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6632 - val_loss: 0.6565\n",
      "Epoch 15/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6615 - val_loss: 0.6530\n",
      "Epoch 16/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6608 - val_loss: 0.6510\n",
      "Epoch 17/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6580 - val_loss: 0.6483\n",
      "Epoch 18/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6582 - val_loss: 0.6521\n",
      "Epoch 19/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6565 - val_loss: 0.6470\n",
      "Epoch 20/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6523 - val_loss: 0.6459\n",
      "Epoch 21/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6586 - val_loss: 0.6446\n",
      "Epoch 22/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6530 - val_loss: 0.6431\n",
      "Epoch 23/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6560 - val_loss: 0.6445\n",
      "Epoch 24/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6569 - val_loss: 0.6440\n",
      "Epoch 25/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6545 - val_loss: 0.6426\n",
      "Epoch 26/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6533 - val_loss: 0.6418\n",
      "Epoch 27/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6515 - val_loss: 0.6420\n",
      "Epoch 28/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6497 - val_loss: 0.6417\n",
      "Epoch 29/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6524 - val_loss: 0.6427\n",
      "Epoch 30/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6487 - val_loss: 0.6423\n",
      "Epoch 31/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6500 - val_loss: 0.6373\n",
      "Epoch 32/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6498 - val_loss: 0.6376\n",
      "Epoch 33/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6453 - val_loss: 0.6397\n",
      "Epoch 34/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6517 - val_loss: 0.6413\n",
      "Epoch 35/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6481 - val_loss: 0.6399\n",
      "Epoch 36/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6496 - val_loss: 0.6426\n",
      "Epoch 37/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6425 - val_loss: 0.6375\n",
      "Epoch 38/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6441 - val_loss: 0.6333\n",
      "Epoch 39/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6471 - val_loss: 0.6371\n",
      "Epoch 40/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6473 - val_loss: 0.6362\n",
      "Epoch 41/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.6340\n",
      "Epoch 42/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6455 - val_loss: 0.6322\n",
      "Epoch 43/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6466 - val_loss: 0.6318\n",
      "Epoch 44/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.6363\n",
      "Epoch 45/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6470 - val_loss: 0.6415\n",
      "Epoch 46/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6457 - val_loss: 0.6313\n",
      "Epoch 47/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6433 - val_loss: 0.6367\n",
      "Epoch 48/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6464 - val_loss: 0.6336\n",
      "Epoch 49/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6447 - val_loss: 0.6351\n",
      "Epoch 50/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6471 - val_loss: 0.6349\n",
      "Epoch 51/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6444 - val_loss: 0.6335\n",
      "Epoch 52/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6474 - val_loss: 0.6318\n",
      "Epoch 53/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6467 - val_loss: 0.6382\n",
      "Epoch 54/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6453 - val_loss: 0.6338\n",
      "Epoch 55/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6448 - val_loss: 0.6354\n",
      "Epoch 56/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6436 - val_loss: 0.6328\n",
      "Epoch 57/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6478 - val_loss: 0.6346\n",
      "Epoch 58/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6453 - val_loss: 0.6361\n",
      "Epoch 59/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6478 - val_loss: 0.6352\n",
      "Epoch 60/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6418 - val_loss: 0.6320\n",
      "Epoch 61/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6475 - val_loss: 0.6360\n",
      "Epoch 62/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.6286\n",
      "Epoch 63/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6436 - val_loss: 0.6323\n",
      "Epoch 64/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6414 - val_loss: 0.6290\n",
      "Epoch 65/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.6325\n",
      "Epoch 66/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6400 - val_loss: 0.6337\n",
      "Epoch 67/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.6310\n",
      "Epoch 68/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6391 - val_loss: 0.6333\n",
      "Epoch 69/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6407 - val_loss: 0.6278\n",
      "Epoch 70/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6425 - val_loss: 0.6335\n",
      "Epoch 71/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6433 - val_loss: 0.6320\n",
      "Epoch 72/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6371 - val_loss: 0.6304\n",
      "Epoch 73/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6418 - val_loss: 0.6339\n",
      "Epoch 74/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6404 - val_loss: 0.6276\n",
      "Epoch 75/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6420 - val_loss: 0.6315\n",
      "Epoch 76/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6443 - val_loss: 0.6297\n",
      "Epoch 77/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6395 - val_loss: 0.6281\n",
      "Epoch 78/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6403 - val_loss: 0.6320\n",
      "Epoch 79/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6405 - val_loss: 0.6299\n",
      "Epoch 80/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6420 - val_loss: 0.6307\n",
      "Epoch 81/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6378 - val_loss: 0.6305\n",
      "Epoch 82/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6451 - val_loss: 0.6319\n",
      "Epoch 83/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6424 - val_loss: 0.6294\n",
      "Epoch 84/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6429 - val_loss: 0.6333\n",
      "Epoch 85/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6409 - val_loss: 0.6319\n",
      "Epoch 86/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6420 - val_loss: 0.6300\n",
      "Epoch 87/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6360 - val_loss: 0.6268\n",
      "Epoch 88/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6421 - val_loss: 0.6292\n",
      "Epoch 89/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6412 - val_loss: 0.6305\n",
      "Epoch 90/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6387 - val_loss: 0.6342\n",
      "Epoch 91/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6407 - val_loss: 0.6281\n",
      "Epoch 92/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6441 - val_loss: 0.6301\n",
      "Epoch 93/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6390 - val_loss: 0.6278\n",
      "Epoch 94/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6434 - val_loss: 0.6347\n",
      "Epoch 95/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6396 - val_loss: 0.6290\n",
      "Epoch 96/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6403 - val_loss: 0.6314\n",
      "Epoch 97/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6387 - val_loss: 0.6273\n",
      "Epoch 98/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6391 - val_loss: 0.6278\n",
      "Epoch 99/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6382 - val_loss: 0.6280\n",
      "Epoch 100/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6375 - val_loss: 0.6324\n",
      "Epoch 101/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6382 - val_loss: 0.6275\n",
      "Epoch 102/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6408 - val_loss: 0.6296\n",
      "Epoch 103/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6374 - val_loss: 0.6271\n",
      "Epoch 104/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6403 - val_loss: 0.6312\n",
      "Epoch 105/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6405 - val_loss: 0.6259\n",
      "Epoch 106/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6410 - val_loss: 0.6292\n",
      "Epoch 107/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6407 - val_loss: 0.6272\n",
      "Epoch 108/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6429 - val_loss: 0.6279\n",
      "Epoch 109/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6398 - val_loss: 0.6310\n",
      "Epoch 110/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6401 - val_loss: 0.6274\n",
      "Epoch 111/600\n",
      "272/272 [==============================] - 1s 2ms/step - loss: 0.6363 - val_loss: 0.6283\n",
      "Epoch 112/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6400 - val_loss: 0.6256\n",
      "Epoch 113/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6368 - val_loss: 0.6292\n",
      "Epoch 114/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6368 - val_loss: 0.6268\n",
      "Epoch 115/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6394 - val_loss: 0.6302\n",
      "Epoch 116/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6407 - val_loss: 0.6322\n",
      "Epoch 117/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6442 - val_loss: 0.6284\n",
      "Epoch 118/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6363 - val_loss: 0.6320\n",
      "Epoch 119/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6406 - val_loss: 0.6263\n",
      "Epoch 120/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6361 - val_loss: 0.6239\n",
      "Epoch 121/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6381 - val_loss: 0.6286\n",
      "Epoch 122/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6377 - val_loss: 0.6341\n",
      "Epoch 123/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6398 - val_loss: 0.6265\n",
      "Epoch 124/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6355 - val_loss: 0.6300\n",
      "Epoch 125/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6371 - val_loss: 0.6245\n",
      "Epoch 126/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6370 - val_loss: 0.6233\n",
      "Epoch 127/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6356 - val_loss: 0.6259\n",
      "Epoch 128/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6385 - val_loss: 0.6283\n",
      "Epoch 129/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6358 - val_loss: 0.6232\n",
      "Epoch 130/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6378 - val_loss: 0.6309\n",
      "Epoch 131/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6419 - val_loss: 0.6311\n",
      "Epoch 132/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6374 - val_loss: 0.6244\n",
      "Epoch 133/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6375 - val_loss: 0.6294\n",
      "Epoch 134/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6357 - val_loss: 0.6262\n",
      "Epoch 135/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6350 - val_loss: 0.6236\n",
      "Epoch 136/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6376 - val_loss: 0.6285\n",
      "Epoch 137/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6396 - val_loss: 0.6273\n",
      "Epoch 138/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6416 - val_loss: 0.6243\n",
      "Epoch 139/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6338 - val_loss: 0.6268\n",
      "Epoch 140/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 0.6249\n",
      "Epoch 141/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6338 - val_loss: 0.6250\n",
      "Epoch 142/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6350 - val_loss: 0.6244\n",
      "Epoch 143/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6399 - val_loss: 0.6269\n",
      "Epoch 144/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6408 - val_loss: 0.6262\n",
      "Epoch 145/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6423 - val_loss: 0.6270\n",
      "Epoch 146/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6360 - val_loss: 0.6303\n",
      "Epoch 147/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6392 - val_loss: 0.6248\n",
      "Epoch 148/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6365 - val_loss: 0.6333\n",
      "Epoch 149/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6433 - val_loss: 0.6314\n",
      "Epoch 150/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6356 - val_loss: 0.6278\n",
      "Epoch 151/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6379 - val_loss: 0.6269\n",
      "Epoch 152/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6343 - val_loss: 0.6249\n",
      "Epoch 153/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6396 - val_loss: 0.6282\n",
      "Epoch 154/600\n",
      "272/272 [==============================] - 0s 2ms/step - loss: 0.6384 - val_loss: 0.6309\n",
      "Epoch 154: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7faea163b310>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.59      0.62      1440\n",
      "           1       0.64      0.71      0.67      1460\n",
      "\n",
      "    accuracy                           0.65      2900\n",
      "   macro avg       0.65      0.65      0.65      2900\n",
      "weighted avg       0.65      0.65      0.65      2900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try XGboost on this data!!\n",
    "\n",
    "# Why is the classification report data not changing after Early Stopping + Drop out Layers?\n",
    "\n",
    "# See about excluding home court (binary variable) from normalization (does that change anything?)\n",
    "\n",
    "# Incorp Opp stats in final feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should I normalize the stats before of after subtracting team stats? (I probably should normalize after)\n",
    "# can maybe cut out pf since that's similar to fta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#games_per_year = {\n",
    "#2014: 83, \n",
    "#2015: 83,\n",
    "#…. }\n",
    "\n",
    "\n",
    "#For year, games in games_per_year.items():\n",
    "#      Df = df.when(date=year).iloc[:games]\n",
    "#      df_1 = df.when(date=year).iloc[games:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#should a normalize before or after taking the difference of the team/g stats? Will normalize after for now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
